<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Statistiques computationnelles</title>
    <meta charset="utf-8" />
    <meta name="author" content=" Charlotte Baey " />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Statistiques computationnelles
]
.author[
### <font size="5"> Charlotte Baey </font>
]
.date[
### <font size="5"> M1 MA - 2024/2025 </font>
]

---


&lt;style&gt;

.remark-slide-content {
  background-color: #FFFFFF;
  border-top: 80px solid #16A085;
  font-size: 20px;
  line-height: 1.5;
  padding: 1em 2em 1em 2em
}

.my-one-page-font {
  font-size: 20px;
}

.remark-slide-content &gt; h1 {
  font-size: 38px;
  margin-top: -85px;
}

.inverse {
  background-color: #16A085;
  border-top: 80px solid #16A085;
  text-shadow: none;
	background-position: 50% 75%;
  background-size: 150px;
  font-size: 40px
}

.title-slide {
  background-color: #16A085;
  border-top: 80px solid #16A085;
  background-image: none;
}

.remark-slide-number {
  position: absolute;
}

.remark-slide-number .progress-bar-container {
  position: absolute;
  bottom: 0;
  height: 4px;
  display: block;
  left: 0;
  right: 0;
}

.remark-slide-number .progress-bar {
  height: 100%;
  background-color: grey;
}

.left-column {
  width: 20%;
  height: 92%;
  float: left;
}
.left-column h2:last-of-type, .left-column h3:last-child {
  color: #000;
}
.right-column {
  width: 75%;
  float: right;
  padding-top: 1em;
}


.left-column2 {
  width: 60%;
  height: 92%;
  float: left;
}
.right-column2 {
  width: 35%;
  height: 92%;
  float: left;
}

&lt;/style&gt;

&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      yellow: ["{\\color{yellow}{#1}}", 1],
      orange: ["{\\color{orange}{#1}}", 1],
      green: ["{\\color{green}{#1}}", 1]
    },
    loader: {load: ['[tex]/color']},
    tex: {packages: {'[+]': ['color']}}
  }
});
&lt;/script&gt;

&lt;style type="text/css"&gt;
.left-code {
  width: 40%;
  height: 92%;
  float: left;
}
.right-plot {
  width: 59%;
  float: right;
  padding-left: 1%;
}
&lt;/style&gt;

&lt;style type="text/css"&gt;
.left-plot {
  width: 59%;
  float: left;
}
.right-code {
  width: 40%;
  float: right;
  padding-left: 1%;
}
&lt;/style&gt;






# Quelques informations pratiques

### Plan du cours
1. Méthodes de ré-échantillonnage
2. Méthodes de Monte-Carlo
3. Introduction aux statistiques bayésiennes
4. Algorithme EM (s'il reste du temps)

### Organisation

- 2 séances de cours d'1h30 par semaine (`\(\times\)` 11 semaines)
- 2 séances de TD/TP de 2h par semaine (`\(\times\)` 12 semaines)

### Evaluation

- 1 DS intermédiaire d'une durée de 2h
- 1 Projet **à effectuer en binôme**
- 1 DS final d'une durée de 3h

.red[**Aucun document autorisé lors des examens.**]

---
# Sommaire

.pull-left[
**1. Méthodes de ré-échantillonnage**
  - [Cours 1](#c1) (13/01/2025)
  - [Cours 2](#c2) (14/01/2025)
  - [Cours 3](#c3) (20/01/2025)
  - [Cours 4](#c4) (21/01/2025)
  - [Cours 5](#c5) (27/01/2025)
  
**2. Méthodes de Monte-Carlo**
  - [Cours 6](#c6) (28/01/2025)
  - [Cours 7](#c7) (03/02/2025)
  - [Cours 8](#c8) (04/02/2025)
  - [Cours 9](#c9) (10/02/2025)
  - [Cours 10](#c10) (11/02/2025)

**3. Méthodes MCMC**
  - [Cours 11](#c11) (24/02/2025)
  - [Cours 12](#c12) (25/02/2025)
]
.pull-right[
**3. Méthodes MCMC (suite)**
  - [Cours 13](#c13) (04/03/2025)
  - [Cours 14](#c14) (10/03/2025)
]

---
name: c1
class: inverse, middle, center

# Introduction


---
class: my-one-page-font 
# C'est quoi les statistiques computationnelles ?

&lt;br&gt;

&lt;br&gt;

 - C'est le recours (plus ou moins) intensif à l'ordinateur pour répondre à des questions statistiques que l'on ne sait pas (ou difficilement) résoudre autrement.
 
 - On utilise/développe/étudie des algorithmes, des astuces numériques/statistiques/computationnelles 
 - L'objectif est de faire de l'inférence, d'étudier la robustesse de méthodes statistiques, de traiter de grands jeux de données, ...
 
 

---

class: inverse, middle, center

# I. Méthodes de ré-échantillonnage

---

# Notion d'échantillon

Qu'est-ce qu'un échantillon ?

- une suite de variables aléatoires `\(\mathcal{X} = (X_1, \dots, X_n)\)`
- dont on observe une réalisation `\(\mathcal{X}(\omega) = (X_1(\omega), \dots, X_n(\omega))\)`

---
# Notion d'échantillon

Qu'est-ce qu'un échantillon ?

- une suite de variables aléatoires `\(\mathcal{X} = (X_1, \dots, X_n)\)`
- dont on observe une réalisation `\(\mathcal{X}(\omega) = (X_1(\omega), \dots, X_n(\omega))\)`

Que représente `\(\omega\)` ?
- l'aléa autour de l'expérience (ex. : `\(n\)` lancers d'une pièce de monnaie)
- cet aléa `\(\omega \in \Omega\)` est transporté dans `\(\mathbb{R}\)` via `\(X_i\)`
&lt;!-- - on a seulement accès à la variabilité sur `\(\mathbb{R}\)` --&gt;
- en général, on ne dispose que d'une seule réalisation, pour un `\(\omega\)` donné

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-4-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-5-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-6-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-7-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-8-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-9-1.png" width="2000px" /&gt;


---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-10-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-11-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-12-1.png" width="2000px" /&gt;

---
# Statistique paramétrique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-13-1.png" width="2000px" /&gt;


---
# Un exemple simple 

Soit `\((X_1,\dots,X_n)\)` un échantillon gaussien i.i.d. de loi `\(\mathcal{N}(\theta,1)\)`, et `\(\hat{\theta}\)` l'EMV de `\(\theta\)`. Quelle est la loi de `\(\hat{\theta}\)` ?

--

.pull-left[

``` r
theta_vrai &lt;- 2; n &lt;- 100; N &lt;- 500
hat_theta &lt;- rep(0,N)
for (i in 1:N){
  ech_i &lt;- rnorm(n,theta_vrai,1)
  hat_theta[i] &lt;- mean(ech_i)
}
hist(hat_theta,freq=F)
curve(dnorm(x,theta_vrai,1/sqrt(n)))
```
]
.pull-right[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-15-1.png" width="432" /&gt;
]
---
class: my-one-page-font 
# Jackknife

Comment construire de nouveaux échantillons ?

&lt;img src="slides_25_files/figure-html/unnamed-chunk-16-1.png" width="720" /&gt;

---
class: my-one-page-font 
# Jackknife

Comment construire de nouveaux échantillons ?

&lt;img src="slides_25_files/figure-html/unnamed-chunk-17-1.png" width="720" /&gt;


---
# Jackknife 

#### 1. Réduction du biais

 - Estimation du biais : 

`$$\hat{b}_{jack} = (n-1)(\hat{\theta}_{jack} - \hat{\theta}),$$` avec `\(\hat{\theta}_{jack} = \frac{1}{n}\sum_{i=1}^n \hat{\theta}_{(i)}\)`.

 - Pseudo-valeurs :

`$$\tilde{\theta}_{(i)} = n\hat{\theta} - (n-1)\hat{\theta}_{(i)}$$`
&lt;!-- Sur l'exemple précédent, cela donne : --&gt;
 &lt;!-- \tilde{\theta}_{(1)} = \tilde{\theta}_{(2)} = \tilde{\theta}_{(3)} = \tilde{\theta}_{(7)} = \tilde{\theta}_{(8)} = \tilde{\theta}_{(10)} = \tilde{\theta}_{(12)} = 13\times0.5384 - 12\times0.50 = 0.9992
 \tilde{\theta}_{(4)} = \tilde{\theta}_{(5)} = \tilde{\theta}_{(6)} = \tilde{\theta}_{(9)} = \tilde{\theta}_{(11)} = \tilde{\theta}_{(13)} = 13\times0.5384 - 12\times0.5833 = -0.0004 --&gt;


 - Estimateur jackknife corrigé du biais :

`$$\hat{\theta}^*_{jack} = \hat{\theta} - \hat{b}_{jack} = \frac{1}{n}\sum_{i=1}^n \tilde{\theta}_{(i)}$$`
.red[**Réduire le biais n'implique pas nécessairement une amélioration de l'estimateur (au sens du risque quadratique)**]


---
# Jackknife

#### 2. Estimation de la variance

 `$$\hat{s}^2_{jack} = \frac{n-1}{n} \sum_{i=1}^n \big(\hat{\theta}_{(i)} - \hat{\theta}^*_{jack}\big)^2$$`
 
avec les pseudo-valeurs : `\(\hat{s}^2_{jack} = \frac{1}{n(n-1)} \sum_{i=1}^n \big(\tilde{\theta}_{(i)} - \tilde{\theta}\big)^2\)`

--

#### 3. Construction d'intervalles de confiance

Si existence d'un TCL :
- en utilisant l'estimateur jackknife de la variance : 
 `$$\hat{I}_{jack} = \left[\hat{\theta} - q^{\mathcal{N(0,1)}}_{1-\alpha/2} \hat{s}_{jack} ; \hat{\theta} + q^{\mathcal{N(0,1)}}_{1-\alpha/2} \hat{s}_{jack} \right]$$`

- en utilisant les deux estimateurs :
  `$$\hat{I}_{jack} = \left[\hat{\theta}_{jack} - q^{\mathcal{N(0,1)}}_{1-\alpha/2} \hat{s}_{jack} ; \hat{\theta}_{jack} + q^{\mathcal{N(0,1)}}_{1-\alpha/2} \hat{s}_{jack} \right]$$`

&lt;span style="color:#16A085"&gt;**fin du cours 1 (13/01/2025)**&lt;/span&gt;


---
name: c2
# Résumé et remarques

&lt;br&gt;
- le jackknife est une méthode **non-paramétrique** permettant d'estimer le biais et la variance d'un estimateur à l'aide de simulations 

- la consistance est garantie pour un grand nombre d'estimateurs **suffisamment réguliers**

- les hypothèses de régularité sont toutefois plus strictes que pour un TCL par exemple :
 - la delta-méthode requiert la différentiabilité de `\(g\)` en `\(\mu=\mathbb{E}(X_1)\)`
 - la consistance de `\(\hat{s}_{jack}\)` requiert que `\(g'\)` soit continue en `\(\mu\)`
 - ex. d'estimateur pour lequel `\(\hat{s}_{jack}\)` n'est pas consistant : la médiane empirique (malgré existence TCL)
 
- extensions possibles reposant sur des hypothèses moins fortes : 
 - le *delete-d* jackknife
 - le jackknife infinitésimal
 &lt;!-- - peut-être utilisé pour la médiane empirique --&gt;
 &lt;!-- - peut permettre d'estimer la distribution de `\(\hat{\theta}\)` --&gt;

&lt;!--&lt;/br&gt;
&lt;span style="color:#16A085"&gt;**fin du cours 1 (22/01/2024)**&lt;/span&gt;--&gt;

---
# Du jackknife au bootstrap

 - `\(\hat{\theta} = T(\underbrace{X_1,\dots,X_n}_{\text{observations}},\underbrace{\omega_1,\dots,\omega_n}_{\text{poids des obs.}}) = T(X_1,\dots,X_n,\frac{1}{n},\dots,\frac{1}{n})\)`
 
 - réplication jackknife : `\(\hat{\theta}_{(i)} = T(X_1,\dots,X_{i-1},X_i,X_{i+1},X_n,\frac{1}{n-1},\dots,\frac{1}{n-1},0,\frac{1}{n-1},\dots,\frac{1}{n-1})\)`

--

 - Idée du bootstrap : mettre des poids **aléatoires**

--

 - Procédure de ré-échantillonnage : tirer uniformément et **avec remise** parmi les observations de `\(\mathcal{X}\)`, pour construire un échantillon *bootstrap* de taille `\(n\)` noté `\(\mathcal{X}^*\)` :
 
 - Puis sur chaque échantillon bootstrap, on construit la statistique bootstrapée `\(\hat{\theta}^* = T(\mathcal{X}^*)\)`

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-18-1.png" width="2000px" /&gt;

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-19-1.png" width="2000px" /&gt;

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-20-1.png" width="2000px" /&gt;


---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-21-1.png" width="2000px" /&gt;

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-22-1.png" width="2000px" /&gt;

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-23-1.png" width="2000px" /&gt;

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-24-1.png" width="2000px" /&gt;

---
# Bootstrap

&lt;img src="slides_25_files/figure-html/unnamed-chunk-25-1.png" width="2000px" /&gt;



---
# Fonction de répartition empirique

 

```
##  [1] -0.88 -0.75  1.38  0.24  0.11  1.20 -0.46  0.64  0.42  0.78
```

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-27-1.png" width="720" /&gt;

---
# Fonction de répartition empirique

 

```
##  [1] -0.88 -0.75  1.38  0.24  0.11  1.20 -0.46  0.64  0.42  0.78
```


&lt;img src="slides_25_files/figure-html/unnamed-chunk-29-1.png" width="720" /&gt;

---

# Fonction de répartition empirique

 - Echantillon exponentiel
 
&lt;img src="slides_25_files/figure-html/unnamed-chunk-30-1.png" width="1152" /&gt;

 - Echantillon uniforme
 
&lt;img src="slides_25_files/figure-html/unnamed-chunk-31-1.png" width="1152" /&gt;

---
# Bootstrap

.pull-left[
### Monde réel
.left[
&lt;span style="color:white"&gt;**on raisonne conditionnellement à `\(F_n\)`**&lt;/span&gt;
- échantillon `\(\mathcal{X} = (X_1,\dots,X_n)\)`
- `\(X_i\)` de loi inconnue `\(F\)`
- paramètre `\(\theta(F)\)`
- estimateur `\(\hat{\theta} = T(\mathcal{X})\)`
- loi de `\(\hat{\theta}\)` : `\(G\)` inconnue
]
]
.pull-right[
### Monde Bootstrap 
.left[
&lt;span style="color:red"&gt;**on raisonne conditionnellement à `\(F_n\)`**&lt;/span&gt;
- échantillon bootstrap `\(\mathcal{X}^* = (X_{1}^*,\dots,X_{n}^*)\)`
- `\(X_{i}^*\)` de loi connue `\(F_n\)`
- paramètre `\(\theta(F_n) = \hat{\theta}\)`
- statistique bootstrapée `\(\hat{\theta}^* = T(\mathcal{X}^*)\)`
- loi de `\(\hat{\theta}^*\)` : `\(G^*\)` connue
]
]

&lt;/br&gt;
.center[
`\(G\)` inconnue `\(\longrightarrow\)` `\(G^*\)` connue `\(\longrightarrow\)` `\(\hat{G}^*_B\)` approximation bootstrap
]

&lt;/br&gt;
&lt;span style="color:#16A085"&gt;**fin du cours 2 (14/01/2025)**&lt;/span&gt;


---
name: c3
# Bootstrap : principe du plug-in

 - on remplace `\(F\)` par sa version empirique `\(F_n\)` 


&lt;img src="slides_25_files/figure-html/unnamed-chunk-32-1.png" width="864" /&gt;
&lt;!-- .pull-left[ --&gt;
&lt;!-- .center[ --&gt;
&lt;!-- espérance : `\(\theta = \int x dF(x)\)` ]]--&gt;
&lt;!-- .pull-right[ --&gt;
&lt;!-- espérance : `\(\int x dF_n(x) = \frac{1}{n} \sum_{i=1}^n X_i\)`] --&gt;

---
# Bootstrap : principe du plug-in

#### Exemple  
`\(\theta = \mathbb{E}(X_1) = \int x dF(x)\)` 

--

Méthode du plug-in : on estime `\(\theta\)` par `\(\hat{\theta} = \int x dF_n(x) = \frac{1}{n}\sum_{i=1}^n X_i\)`.

--

Dans l'échantillon bootstrap, les `\(X_{b,i}^*\)` sont distribuées selon la loi `\(F_n\)`, et ont pour espérance

`\(\theta^* = \int x dF_n(x) = \hat{\theta}\)`

--

La statistique bootstrapée `\(\hat{\theta}^*_b = \frac{1}{n}\sum_{i=1}^n X_{b,i}^*\)` est donc à `\(\theta^*\)` ce que `\(\hat{\theta}\)` est à `\(\theta\)`.

---
# Bootstrap 

#### Exemple 2 : estimation du biais de `\(\hat{\theta}\)`

Paramètre `\(\theta(F)\)` estimé par `\(\hat{\theta} = \theta(F_n)\)`

--

Biais : `\(b(\hat{\theta}) = \mathbb{E}_F(\hat{\theta}) - \theta = \int xdG(x) - \theta(F)\)`

--

Dans le monde bootstrap : 

`$$b^*(\hat{\theta}) = \int x dG^*(x) - \theta(F_n) = \int x dG^*(x) - \hat{\theta}$$`

--

Estimateur du bootstrap :

`$$\hat{b}^*(\hat{\theta}) = \int x d\hat{G}^*_B(x) - \hat{\theta} = \frac{1}{B} \sum_{i=1}^B \hat{\theta}^*_b - \hat{\theta}$$`

---
# Bootstrap

#### Exemple 3 : estimation de la variance de `\(\hat{\theta}\)`

Variance : `\(\text{Var} (\hat{\theta}) = \mathbb{E}_F\big[(\hat{\theta} - \mathbb{E}(\hat{\theta}))^2\big] = \int (x - \int x dG(x))^2dG(x)\)`

--

Dans le monde bootstrap :

`$$\text{Var}^*(\hat{\theta}) = \int (x - \int x dG^*(x))^2 dG^*(x)$$`

--

Estimateur du bootstrap :

`$$\hat{\text{Var}}^*(\hat{\theta}) = \int (x - \int x d\hat{G}_B^*(x))^2 d\hat{G}_B^*(x) = \frac{1}{B} \sum_{b=1}^B \big(\hat{\theta}^*_b - \frac{1}{B} \sum_{b=1}^B \hat{\theta}^*_b \big)^2$$`

`\(\rightarrow\)` c'est la variance empirique des statistiques bootstrapées `\(\hat{\theta}^*_1,\dots,\hat{\theta}^*_B\)`.

&lt;/br&gt;
&lt;span style="color:#16A085"&gt;**fin du cours 3 (20/01/2025)**&lt;/span&gt;

---
name: c4
# Construction d'intervalles de confiance

#### Méthode du bootstrap classique
Point de départ : l'existence d'une quantité pivotale, par exemple `\(\hat{\theta} - \theta\)`, de loi `\(H\)`.

--
 
&lt;img src="slides_25_files/figure-html/unnamed-chunk-33-1.png" width="360" /&gt;
 
--

IC : `\(I(1-\alpha) =  \big[\hat{\theta} - H^{-1}(1-\alpha/2); \hat{\theta} - H^{-1}(\alpha/2)\big]\)`
 
---
# Construction d'intervalles de confiance
 
Version bootstrap empirique : `\(\hat{I}^*(1-\alpha) =  \big[\hat{\theta} - (\hat{H}^*_B)^{-1}(1-\alpha/2); \hat{\theta} - (\hat{H}^*_B)^{-1}(\alpha/2)\big]\)`
 
#### Calcul des quantiles de `\(\hat{H}^*_B\)`
 
 - `\(H^*(x) = G^*(x + \hat{\theta})\)`
 
--
 
&lt;img src="slides_25_files/figure-html/unnamed-chunk-34-1.png" width="504" /&gt;

--
 
 - `\((H^*)^{-1}(y) = (G^*)^{-1}(y) - \hat{\theta}\)`
 
---
# Construction d'intervalles de confiance

#### Méthode du bootstrap classique

`$$\hat{I}_{boot}^*(1-\alpha) =  \big[2\hat{\theta} - \hat{\theta}^*_{(\lceil B(1-\alpha/2)\rceil )} ; 2\hat{\theta} - \hat{\theta}^*_{(\lceil B \alpha/2\rceil )}  \big]$$`
---
# Construction d'intervalles de confiance

#### Méthode percentile

&lt;span style="color:red"&gt;Hypothèse : il existe une transformation `\(h\)` **croissante** telle que la loi de `\(h(\hat{\theta})\)` soit symétrique autour de `\(\eta = h(\theta)\)`&lt;/span&gt;


IC pour `\(\eta\)` : 
$$IC_\eta(1-\alpha) = \left[U - H^{-1}_U\left( 1 - \frac{\alpha}{2}\right) ; U - H^{-1}_U \left(\frac{\alpha}{2}\right)\right]. $$

 - `\(h\)` inconnue ?
 - `\(H_U\)` inconnue ?

---
# Construction d'intervalles de confiance

Démarche :
 1. construire les échantillons bootstrap `\(\mathcal{X}_1^*, \dots, \mathcal{X}_B^*\)`
 2. construire les statistiques bootstrapées `\(\hat{\theta}^*_1, \dots, \hat{\theta}^*_B\)` et leurs transformations par `\(h\)` : `\(U_b^* = h(\hat{\theta}^*_b), \forall b\)`
 3. définir la fonction de répartition de la statistique bootstrap : `$$H^*_{U} (x) = \mathbb{P}(U_b^* - U \leq x \mid F_n)$$`
 4. intervalle de confiance bootstrap pour `\(\eta = h(\theta)\)` : `$$IC_\eta^*(1-\alpha) = \left[U - H^{*-1}_{U}\left(1 -\frac{\alpha}{2} \right) ; U - H^{* \ -1}_{U}\left(\frac{\alpha}{2} \right) \right]$$`
 
 
 
---
# Construction d'intervalles de confiance

.pull-left[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-35-1.png" width="360" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
`\(H^{* \ -1}_{U}\left(\frac{\alpha}{2} \right) = - H^{* \ -1}_{U}\left(1 - \frac{\alpha}{2} \right)\)`
]

`$$IC_{\eta}^*(1-\alpha) = \left[U + H^{*-1}_{U}\left(\frac{\alpha}{2} \right) ; U + H^{* \ -1}_{U}\left(1-\frac{\alpha}{2} \right) \right]$$`

--

`$$IC_{\eta}^*(1-\alpha) = \left[G^{*-1}_{U}\left(\frac{\alpha}{2} \right) ; G^{* \ -1}_{U}\left(1-\frac{\alpha}{2} \right) \right]$$`
&lt;span style="color:#16A085"&gt;**fin du cours 4 (21/01/2025)**&lt;/span&gt;


---
name: c5
# Construction d'intervalles de confiance

#### Méthode percentile

`$$\hat{I}_{perc}^*(1-\alpha) =  \big[\hat{\theta}^*_{(\lceil B\alpha/2\rceil )} ; \hat{\theta}^*_{(\lceil B(1- \alpha/2)\rceil )}  \big]$$`
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;




---
# Construction d'intervalles de confiance

#### Méthode `\(t\)`-percentile

Repose sur l'existence d'une quantité pivotale de la forme (de loi notée `\(J_n\)`):

`$$S_n = \sqrt{n} \ \frac{\hat{\theta} - \theta}{\hat{\sigma}}$$`
--

IC classique : `\(IC(1-\alpha) = \left[\hat{\theta} - \frac{\hat{\sigma}}{\sqrt{n}} J_n^{-1}\left(1-\frac{\alpha}{2}\right) ; \hat{\theta} - \frac{\hat{\sigma}}{\sqrt{n}} J_n^{-1}\left(\frac{\alpha}{2}\right) \right]\)`


--

Démarche bootstrap :
1. construire les échantillons bootstrap `\(\mathcal{X}_1^*, \dots, \mathcal{X}_B^*\)`
2. construire les statistiques bootstrapées `\(S^*_b = \sqrt{n} \ \frac{\hat{\theta}^*_b - \hat{\theta}}{\hat{\sigma}^*_b}, \quad b=1,\dots,B\)`
3. approcher `\(J_n^{-1}\)` par les quantiles empiriques des statistiques bootstrapées
	
	
`$$\hat{I}_{t-\text{boot}}^*(1-\alpha) =  \left[\hat{\theta} - \frac{\hat{\sigma}}{\sqrt{n}} S^*_{\big(\lceil B(1-\frac{\alpha}{2})\rceil\big)}; \hat{\theta} - \frac{\hat{\sigma}}{\sqrt{n}} S^*_{\big(\lceil B(\frac{\alpha}{2})\rceil \big)} \right]$$`

---
# Intervalles de confiance bootstrap

- IC du bootstrap classique :
`$$\hat{I}_{boot}^*(1-\alpha) =  \big[2\hat{\theta} - \hat{\theta}^*_{(\lceil B(1-\alpha/2)\rceil )} ; 2\hat{\theta} - \hat{\theta}^*_{(\lceil B \alpha/2\rceil )}  \big]$$`

- IC du bootstrap percentile :
 `$$\hat{I}_{perc}^*(1-\alpha) =  \big[\hat{\theta}^*_{(\lceil B\alpha/2\rceil )} ; \hat{\theta}^*_{(\lceil B(1- \alpha/2)\rceil )}  \big]$$`
 
- IC du bootstrap `\(t\)`-percentile :
 `$$\hat{I}_{t-\text{boot}}^*(1-\alpha) =  \left[\hat{\theta} - \frac{\hat{\sigma}}{\sqrt{n}} S^*_{(\lceil B(1-\frac{\alpha}{2})\rceil)}; \hat{\theta} - \frac{\hat{\sigma}}{\sqrt{n}} S^*_{(\lceil B(\frac{\alpha}{2})\rceil)} \right]$$`


---
# Paramétrique ou non paramétrique ?

- Jusqu'à présent, on a décrit des procédures de bootstrap dit **non-paramétrique**

--

- En effet, on n'a fait aucune hypothèse sur la loi `\(F\)`, ni exploité sa forme paramétrique

--

- Au contraire, on a échantillonné les `\(X_{b,i}^*\)` selon la loi `\(F_n\)`, qui est un estimateur **non-paramétrique** de `\(F\)`

 &lt;/br&gt;
 
--

- Il est possible de faire du bootstrap **paramétrique**

--

- Dans ce cas, on va utiliser la forme paramétrique de la loi `\(F\)`, que l'on note `\(F_\theta\)`.

--

- On échantillonne alors les `\(X_{b,i}^*\)` selon la loi `\(F_{\hat{\theta}}\)`, qui est un estimateur **paramétrique** de `\(F\)`

&lt;!-- &lt;table&gt; --&gt;
&lt;!--   &lt;tr style="font-weight:bold"&gt; --&gt;
&lt;!--     &lt;td&gt; &lt;/td&gt; --&gt;
&lt;!--     &lt;td&gt;Bootstrap non paramétrique&lt;/td&gt; --&gt;
&lt;!--     &lt;td&gt;Bootstrap paramétrique&lt;/td&gt; --&gt;
&lt;!--   &lt;/tr&gt; --&gt;
&lt;!--   &lt;tr&gt; --&gt;
&lt;!--     &lt;td&gt;hypothèse sur `\(F\)`&lt;/td&gt; --&gt;
&lt;!--     &lt;td&gt;pas d'hypothèse particulière&lt;/td&gt; --&gt;
&lt;!--     &lt;td&gt;$F = F_\theta$&lt;/td&gt; --&gt;
&lt;!--   &lt;/tr&gt; --&gt;
&lt;!-- &lt;tr&gt; --&gt;
&lt;!--     &lt;td&gt;échantillonnage&lt;/td&gt; --&gt;
&lt;!--     &lt;td&gt;selon loi `\(F_n\)`&lt;/td&gt; --&gt;
&lt;!--     &lt;td&gt;selon loi `\(F_{\hat{\theta}}\)`&lt;/td&gt; --&gt;
&lt;!--   &lt;/tr&gt;   --&gt;
&lt;!-- &lt;/table&gt; --&gt;

&lt;/br&gt;

--

.center[.red[**RQ : c'est parfois la seule approche possible**]]

---
# Tests bootstrap

Procédure de test usuelle pour un test de niveau `\(\alpha\)` :

--

- choix des hypothèses `\(H_0\)` et `\(H_1\)`

--

- choix d'une statistique de test `\(T(\mathcal{X})\)`

--

- identification de la loi (éventuellement asymptotique) de `\(T(\mathcal{X})\)`

--

- déterminer la région de rejet **ou** calculer la `\(p\)`-valeur du test

--

- conclure

&lt;/br&gt;
--

.center[.red[&amp;rarr;** quelles sont les difficultés possibles ?**]]

---
# Tests bootstrap

Procédure de test usuelle pour un test de niveau `\(\alpha\)` :


- choix des hypothèses `\(H_0\)` et `\(H_1\)` .green[**&amp;rarr; ok**]


- choix d'une statistique de test `\(T(\mathcal{X})\)` .green[**&amp;rarr; ok**]


- identification de la loi (éventuellement asymptotique) de `\(T(\mathcal{X})\)` .red[**&amp;rarr; loi inconnue**]

- déterminer la région de rejet **ou** calculer la `\(p\)`-valeur du test .red[**&amp;rarr; non calculable**]


- conclure


---
# Tests bootstrap

#### Exemple avec du bootstrap non paramétrique

`\(X_1,\dots,X_n\)` i.i.d. de loi `\(F_1\)` et `\(Y_1,\dots,Y_m\)` i.i.d. de loi `\(F_2\)`.

`$$H_0 : F_1 =  F_2 \quad \text{vs.} \quad H_1 : F_1 \neq F_2$$`
 
--

On suppose que :
 - l'égalité en loi se traduit par une égalité de certains paramètres
--

 - l'on dispose d'une statistique de test `\(T(\mathcal{X})\)` 

--

&lt;/br&gt;
**Objectif** : construire une version bootstrap de `\(T\)` &lt;span style="color:red"&gt;**sous `\(H_0\)`**&lt;/span&gt;

---
# Tests bootstrap

#### Exemple avec du boostrap paramétrique

`\(X_1,\dots,X_n\)` i.i.d. de loi `\(F_{\theta,\eta}\)`, et

`$$H_0 : \theta =  \theta_0 \quad \text{vs.} \quad H_1 : \theta \neq \theta_0$$`

&amp;rarr; `\(\eta\)` est un *paramètre de nuisance*.

&lt;/br&gt;
--

Exemple du TRV :

$$ T(X_1,\dots,X_n) = \frac{L(X_1,\dots,X_n ; \hat{\theta}, \hat{\eta}_1)}{L(X_1,\dots,X_n ; \theta_0, \hat{\eta}_0)},$$
&lt;/br&gt;
--

&lt;span style="color:red"&gt;**&amp;rarr; la loi de `\(T\)` sous `\(H_0\)` n'est pas connue en présence de paramètres de nuisnace**&lt;/span&gt;

&lt;/br&gt;
&lt;span style="color:#16A085"&gt;**fin du cours 5 (27/01/2025)**&lt;/span&gt;

---
name: c6
class: inverse, middle, center

# II. Méthodes de Monte-Carlo

---
# Un peu d'histoire ...

- première expérience de type Monte Carlo dûe à Buffon au XVIIIème siècle &amp;rarr; l'aiguille de Buffon

.center[
&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Buffon_needle.svg/1920px-Buffon_needle.svg.png" width="200" align="center"&gt;]

--

- les méthodes actuelles sont nées pendant la seconde guerre mondiale au laboratoire américain de Los Alamos &amp;rarr; nom de code *Monte-Carlo*

.center[
&lt;img src="https://frenchriviera.travel/wp-content/uploads/2018/03/Monte-Carlo-Casino1.jpg" width="300" align="center"&gt;
]



---
# Objectif

- Question principale : **l'approximation d'intégrales**

$$\int h(x) dx $$

- Outil théorique à la base des méthodes de Monte-Carlo : **la loi forte des grands nombres**

- Outil pratique nécessaire : **la simulation de variables aléatoires**


---

class: inverse, middle, center

# 1. Génération de variables aléatoires

---
# Génération de variables aléatoires

Lois usuelles &amp;rarr; disponibles sous la plupart des langages ou logiciels 




``` r
# Sous R
rexp(n=10, rate=1/5)
```

```
##  [1] 2.3466261 1.9510857 5.9010095 0.4384056 0.2316887 0.4712571 0.5493962
##  [8] 3.1169243 1.4005475 1.2041220
```


``` python
# Sous Python
from scipy.stats import expon
expon.rvs(scale=5, size=10)
```

.red[**attention aux conventions utilisées dans chaque langage !**]

---
#  Méthode de la fonction inverse

Repose sur le résultat suivant :
&gt; Soit `\(F\)` une f.d.r. et `\(F^{-}\)` son inverse (généralisée). Soit `\(U \sim \mathcal{U}([0,1])\)`. Alors `\(X = F^{-}(U)\)` suit la loi `\(F\)`.

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-39-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
#  Méthode de la fonction inverse

Repose sur le résultat suivant :
&gt; Soit `\(F\)` une f.d.r. et `\(F^{-}\)` son inverse (généralisée). Soit `\(U \sim \mathcal{U}([0,1])\)`. Alors `\(X = F^{-}(U)\)` suit la loi `\(F\)`.


&lt;img src="slides_25_files/figure-html/unnamed-chunk-40-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
#  Méthode de la fonction inverse

Repose sur le résultat suivant :
&gt; Soit `\(F\)` une f.d.r. et `\(F^{-}\)` son inverse (généralisée). Soit `\(U \sim \mathcal{U}([0,1])\)`. Alors `\(X = F^{-}(U)\)` suit la loi `\(F\)`.

&lt;img src="slides_25_files/figure-html/unnamed-chunk-41-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
#  Méthode de la fonction inverse

Repose sur le résultat suivant :
&gt; Soit `\(F\)` une f.d.r. et `\(F^{-}\)` son inverse (généralisée). Soit `\(U \sim \mathcal{U}([0,1])\)`. Alors `\(X = F^{-}(U)\)` suit la loi `\(F\)`.

&lt;img src="slides_25_files/figure-html/unnamed-chunk-42-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
# Exemple

Loi de Cauchy, de densité `\(f(x) = \frac{1}{\pi(1+x^2)}\)`

--


``` r
u &lt;- runif(10000)
finv &lt;- function(u){tan(pi*(u-0.5))}
x &lt;- finv(u)
```

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-44-1.png" width="432" style="display: block; margin: auto;" /&gt;


---
# Méthode d'acceptation-rejet

Proposition :
&gt; Soit `\(X\)` une v.a. de densité `\(f\)` et soit `\(g\)` une densité de probabilité et une constante `\(M \geq 1\)` t.q. `\(\forall x, f(x) \leq M g(x)\)`. Alors pour simuler selon la loi `\(f\)` il suffit de :
1. simuler `\(Y \sim g\)`
2. simuler `\(U | Y=y \sim \mathcal{U}([0,Mg(y)])\)`
3. si `\(0 &lt; U &lt; f(Y)\)`, poser `\(X=Y\)`, sinon reprendre l'étape 1.

*Preuve*  &lt;div class="horizontalgap" style="width:10px"&gt;&lt;/div&gt; 

--

Remarques :
- on a seulement besoin de connaître `\(f\)` à une constante multiplicative près
- `\(\forall x, f(x) \leq M g(x) \Rightarrow \text{supp}(f) \subset \text{supp}(g)\)`
- probabilité d'accepter un candidat : `\(\frac{1}{M}\)` (influence du choix de `\(g\)`)


&lt;span style="color:#16A085"&gt;**fin du cours 6 (28/01/2025)**&lt;/span&gt;


---
name: c7
# Méthode d'acceptation-rejet

Illustration

&lt;img src="slides_25_files/figure-html/unnamed-chunk-45-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# Méthode d'acceptation-rejet

- Tirage de `\(Y\)` selon la loi `\(g\)`

&lt;img src="slides_25_files/figure-html/unnamed-chunk-46-1.png" width="720" style="display: block; margin: auto;" /&gt;


---
# Méthode d'acceptation-rejet

- Tirage de `\(U\)` conditionnellement à `\(Y=y\)` selon la loi `\(\mathcal{U}([0,Mg(y)])\)` &amp;rarr; on rejette

&lt;img src="slides_25_files/figure-html/unnamed-chunk-47-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# Méthode d'acceptation-rejet

- Tirage de `\(U\)` conditionnellement à `\(Y=y\)` selon la loi `\(\mathcal{U}([0,Mg(y)])\)` &amp;rarr; on accepte 

&lt;img src="slides_25_files/figure-html/unnamed-chunk-48-1.png" width="720" style="display: block; margin: auto;" /&gt;



---
# Méthode d'acceptation-rejet

A la fin :

&lt;img src="slides_25_files/figure-html/unnamed-chunk-49-1.png" width="720" style="display: block; margin: auto;" /&gt;



---
# Exemple 

On veut simuler `\(X\)` selon la loi normale centrée réduite à l'aide d'une loi exponentielle de paramètre 1.

1. par symétrie de la loi normale, il suffit de savoir simuler selon la loi de `\(|X|\)` 

--

2. on génère ensuite `\(Z\)`, une Bernoulli de paramètre 1/2 et on pose `\(X = |X|\)` si `\(Z=1\)` et `\(X=-|X|\)` si `\(Z=0\)`.

--

3. il faut trouver une constante `\(M\)` telle que `\(f(x)\leq M g(x)\)` pour tout `\(x\)` avec :
- densité cible `\(f(x) = \frac{2}{\sqrt{2\pi}} e^{-x^2/2} \mathbb{1}_{x\geq 0}\)`
- densité de la loi exponentielle `\(g(x) = e^{-x} \mathbb{1}_{x&gt;0}\)`


---
class: my-one-page-font
# Exemple


``` r
n &lt;- 1000
f &lt;- function(x){ifelse(x&gt;0,sqrt(2/pi)*exp(-x^2/2),0)}
g &lt;- function(x){ifelse(x&gt;0,exp(-x),0)}

M &lt;- sqrt(2*exp(1)/pi) # env. 1.31 -&gt; 1/M = 0.76
U1 &lt;- runif(n)
Y &lt;- -log(U1)
U2 &lt;- runif(n,min = 0, max = M*g(Y))
absX &lt;- Y[U2&lt;f(Y)]
Z &lt;- 2*rbinom(length(absX),size = 1, p=1/2) - 1
X &lt;- Z*absX
```

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-51-1.png" width="648" style="display: block; margin: auto;" /&gt;

---
# Un cas particulier

Un cas particulier intéressant : le cas `\(f\)` bornée à support compact.

--

- on prend pour `\(g\)` la loi uniforme sur le support de `\(f\)`
- et on simule `\(U\)` uniforme sur `\([0,m]\)` où `\(m=\max_x f(x)\)`

--

ex. : `\(\displaystyle f(x) = \frac{1}{8} |x^4 - 5x^2 + 4| \ \mathbb{1}_{[-2,2]}(x)\)`
&lt;img src="slides_25_files/figure-html/unnamed-chunk-52-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Un cas particulier

Un cas particulier intéressant : le cas `\(f\)` bornée à support compact.

- on prend pour `\(g\)` la loi uniforme sur le support de `\(f\)`
- et on simule `\(U\)` uniforme sur `\([0,m]\)` où `\(m=\max_x f(x)\)`

ex. : `\(\displaystyle f(x) = \frac{1}{8} |x^4 - 5x^2 + 4| \ \mathbb{1}_{[-2,2]}(x)\)`
&lt;img src="slides_25_files/figure-html/unnamed-chunk-53-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Un cas particulier

`\(f(x) = \frac{1}{8} |x^4 - 5x^2 + 4| \ \mathbb{1}_{[-2,2]}(x)\)`

.pull-left[

``` r
Y &lt;- runif(10000,-2,2)
U &lt;- runif(10000,0,0.5)

accept &lt;- (U&lt;fdens(Y))
X &lt;- Y[accept]

hist(X,breaks=50,freq=F)
points(x,fx,type="l",col="red")
```




``` r
mean(accept)
```

```
## [1] 0.4954
```

&amp;rarr; la moitié des points simulés est 'perdue'
]

.pull-right[
![](slides_25_files/figure-html/unnamed-chunk-57-1.png)&lt;!-- --&gt;
]


---
# Un cas particulier

Visuellement : on peut représenter les points acceptés dans le rectangle `\([-2,2] \times [0,1/2]\)`

&lt;/br&gt;

&lt;img src="slides_25_files/figure-html/unnamed-chunk-58-1.png" style="display: block; margin: auto;" /&gt;

---

class: inverse, middle, center

# 2. Méthodes de Monte-Carlo

---
# Monte Carlo classique

**Objectif** : calculer une intégrale de la forme `\(\int h(x) f(x) dx\)` où `\(f\)` est une densité de probabilité.

--

&gt; *Définition.* Soit `\(X_1,\dots,X_n\)` un échantillon i.i.d. de loi `\(f\)`. L'estimateur de Monte Carlo de `\(\mathbb{E}(h(X))\)` est :
`$$\hat{h}_n = \frac{1}{n} \sum_{i=1}^n h(X_i)$$`


Propriétés :
- estimateur sans biais
- fortement consistant
- IC avec le TCL

Remarques :
- vitesse de convergence en `\(\sqrt{n}\)`, indépendante de la dimension
- ne dépend pas de la régularité de `\(h\)`

---
# Exemples d'applications

#### Approcher la `\(p\)`-valeur d'un test

ex. avec le test du rapport de vraisemblance d'un modèle gaussien :
`$$H_0 : \quad (\mu,\sigma^2)=(\mu_0,\sigma_0^2)\quad\textrm{ contre }\quad H_1 : \quad (\mu,\sigma^2)\neq(\mu_0,\sigma_0^2).$$`

--

On a la statistique de test suivante (voir DS de Stat Math 2024) : 
`$$2\ln V_n= T_n^2-n\ln T_n^2 + Z^2 + n\ln n -n,$$`

avec `\(Z=\sqrt{n}\big(\frac{\hat{\mu}_n-\mu_0}{\sigma_0}\big) \quad \textrm{et}\quad T_n^2=\frac{n\hat{\sigma}^2_n}{\sigma_0^2}\)`.

Problème : la loi de la statistique de test n'est pas connue (tabulée).

---
# Exemples d'applications

Les données :

```
##  [1]  98.23  97.91  98.24  99.00 102.64 103.44 103.81 100.64 100.86  98.79
## [11] 103.48  98.10 101.11  98.30  96.56  98.77 100.15 101.58  97.51 100.87
## [21] 101.99  98.59  98.72 103.97  94.75  97.92 102.30  96.88 101.44 100.12
```
--

.pull-left[

``` r
Tn2 &lt;- (n-1)*var(x)/4
V_obs &lt;- Tn2 - n*log(Tn2) + n*(mean(x)-100)^2/4 + n*log(n) - n
print(V_obs)
```

```
## [1] 1.600647
```

``` r
N &lt;- 100000
T &lt;- rchisq(N,n-1)   
Z &lt;- rnorm(N,0,1)    
V &lt;- T - n*log(T) + Z^2 + n*log(n) - n
p_val &lt;- mean(V &gt; V_obs)
print(p_val)
```

```
## [1] 0.45853
```
]
.pull-right[
![](slides_25_files/figure-html/unnamed-chunk-61-1.png)&lt;!-- --&gt;
]

---
# Exemples d'applications

On peut quantifier l'erreur d'approximation :

.pull-left[

``` r
N &lt;- c(100,1000,2000,5000,10000,20000,
       50000,100000,200000,300000)
p_val &lt;- rep(0,length(N))
for (i in 1:length(N)){
  T &lt;- rchisq(N[i],n-1)   
  Z &lt;- rnorm(N[i],0,1)    
  V &lt;- T-n*log(T)+Z^2+n*log(n)-n
  p_val[i] &lt;- mean(V &gt; V_obs)
}
```
]
.pull-right[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-63-1.png" width="432" /&gt;
]

---
# Exemples d'application

Plus généralement, les méthodes de Monte Carlo s'utilisent pour :

- approcher le niveau ou la puissance d'un test

- approcher une intégrale en grande dimension

- faire de l'optimisation (e.g. algorithme du recuit simulé, descente de gradient stochastique, ...)

- ...

&lt;span style="color:#16A085"&gt;**fin du cours 7 (03/02/2025)**&lt;/span&gt;

---
name: c8
# Monte Carlo classique

Estimation de `\(\mu = \int h(x) f(x) dx\)` à l'aide d'un échantillon `\(X_1,\dots,X_n\)` i.i.d. de loi `\(f\)` :
`$$\hat{h}_n = \frac{1}{n} \sum_{i=1}^n h(X_i),$$`

--

 - estimateur sans biais, fortement consistant
 - variance :
 `$$\text{Var} (\hat{h}_n) = \frac{1}{n} \left(\int h^2(x)f(x)dx - \mu^2\right) = \frac{\sigma_f^2}{n}$$`
 - `\(\sigma_f^2\)` estimée par : `$$v_n = \frac{1}{n} \sum_{i=1}^n h^2(X_i) - \hat{h}_n^2$$`
 - IC de niveau `\(1-\alpha\)` : `$$\hat{I}_\mu =\left[\hat{h}_n - q_{1-\alpha/2}^{\mathcal{N}(0,1)} \sqrt{v_n/n} ; \hat{h}_n + q_{1-\alpha/2}^{\mathcal{N}(0,1)} \sqrt{v_n/n} \right]$$`


---
# Monte Carlo classique

**Exemple :** on veut calculer `\(\int_0^{2\pi} (\sin^2(x) + 2\cos(3x))^2 dx\)`

--
&lt;img src="slides_25_files/figure-html/unnamed-chunk-64-1.png" width="504" style="display: block; margin: auto;" /&gt;

On peut ré-écrire l'intégrale sous la forme  
$$
`\begin{eqnarray}
I &amp; = &amp; 2\pi \int_{\mathbb{R}} (\sin^2(x) + 2\cos(3x))^2 \frac{1}{2\pi}1_{[0,2\pi]}(x)dx \\
&amp; = &amp; 2\pi \ \mathbb{E}((\sin^2(X) + 2\cos(3X))^2), \quad X \sim \mathcal{U}([0,2\pi])
\end{eqnarray}`
$$

---
# Monte Carlo classique

**Exemple :** on veut calculer `\(I=2\pi \ \mathbb{E}((\sin^2(X) + 2\cos(3X))^2), \quad X \sim \mathcal{U}([0,2\pi])\)`

On peut utiliser l'estimateur de Monte-Carlo suivant :
 1. on génère `\(X_1,\dots,X_n\)` i.i.d. de loi uniforme sur `\([0,2\pi]\)`


&lt;img src="slides_25_files/figure-html/unnamed-chunk-65-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Monte Carlo classique

**Exemple :** on veut calculer `\(I=2\pi \ \mathbb{E}((\sin^2(X) + 2\cos(3X))^2), \quad X \sim \mathcal{U}([0,2\pi])\)`

On peut utiliser l'estimateur de Monte-Carlo suivant :
 1. on génère `\(X_1,\dots,X_n\)` i.i.d. de loi uniforme sur `\([0,2\pi]\)`


&lt;img src="slides_25_files/figure-html/unnamed-chunk-66-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Monte Carlo classique

**Exemple :** on veut calculer `\(I=2\pi \ \mathbb{E}((\sin^2(X) + 2\cos(3X))^2), \quad X \sim \mathcal{U}([0,2\pi])\)`

On peut utiliser l'estimateur de Monte-Carlo suivant :
 1. on génère `\(X_1,\dots,X_n\)` i.i.d. de loi uniforme sur `\([0,2\pi]\)`
 2. on approche `\(I\)` par `\(\hat{I} = 2 \pi \frac{1}{n}\sum_{i=1}^n (\sin^2(X_i) + 2\cos(3X_i))^2\)`

&lt;img src="slides_25_files/figure-html/unnamed-chunk-67-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Monte Carlo classique

&lt;img src="slides_25_files/figure-html/unnamed-chunk-68-1.png" width="504" style="display: block; margin: auto;" /&gt;
On trouve : 

```
## [1] "Estimation :16.56502, variance :2.22047, IC = [13.644,19.486]"
```

```
## [1] "La vraie valeur est : 14.92257"
```

---

class: inverse, middle, center

# 3. Echantillonnage préférentiel

---
# Echantillonnage préférentiel

**Objectif** : toujours d'évaluer `\(\mu = \int h(x) f(x) dx\)`


On va **ré-écrire l'intégrale** sous la forme :

`$$\mu = \int h(x) f(x) dx = \int h(x) \frac{f(x)}{g(x)} g(x) dx,$$`
avec `\(g\)` densité de probabilité, telle que `\((g(x) = 0) \Rightarrow (h(x)f(x) = 0)\)`.

--

Pourquoi ?

 - pas toujours possible de simuler selon la loi `\(f\)`, ou d'utiliser la méthode d'acceptation-rejet
 - ou on s'intéresse à un évènement de probabilité trop faible
 - dans certains cas cela permet de réduire la variance de l'estimateur

---
# Echantillonnage préférentiel

&gt; *Définition.* Soit `\(Z_1,\dots,Z_n\)` un échantillon i.i.d. de loi `\(g\)`. L'estimateur par échantillonnage préférentiel de `\(\mu\)` est :
`$$\tilde{\mu}_n = \frac{1}{n} \sum_{i=1}^n h(Z_i) \frac{f(Z_i)}{g(Z_i)} = \frac{1}{n} \sum_{i=1}^n w_i h(Z_i)$$`

Propriétés : (si `\(\text{supp}(f) \subset \text{supp}(g)\)`)

- estimateur sans biais
- fortement consistant

Remarques :

- On appelle *poids d'importance* les quantités `\(w_i = \frac{f(Z_i)}{g(Z_i)}\)`
- La loi `\(g\)` est appelée *loi instrumentale*


---
class: my-one-page-font
# Echantillonnage préférentiel

**Exemple 1** : on veut calculer `\(\int_0^1 e^{-x}x^{-a} dx\)` pour `\(0 &lt; a &lt; 1\)`.

--

Monte Carlo classique &amp;rarr; `\(f\)` densité de la loi uniforme sur `\([0,1]\)` et `\(h(x) = e^{-x}x^{-a}\)`.

--


``` r
set.seed(04022025)
a &lt;- 1/2
n &lt;- 1000
X &lt;- runif(n)
hX &lt;- exp(-X) * X^(-a)
print(paste0("Estimation : ",mean(hX),", variance : ",var(hX)/n))
```

```
## [1] "Estimation : 1.51278946224264, variance : 0.00492448440750204"
```

--

Peut-on faire mieux ? 

---
# Echantillonnage préférentiel

A quoi ressemble la fonction `\(h(x) = e^{-x}x^{-a}\)` ?

&lt;img src="slides_25_files/figure-html/unnamed-chunk-71-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Echantillonnage préférentiel

A quoi ressemble la fonction `\(h(x) = e^{-x}x^{-a}\)` ? 

&lt;img src="slides_25_files/figure-html/unnamed-chunk-72-1.png" width="504" style="display: block; margin: auto;" /&gt;
&amp;rarr; en échantillonnant selon la loi uniforme, on obtient des points répartis de façon **uniforme** sur `\([0,1]\)`.

&amp;rarr; Peut-on trouver une loi d'échantillonnage qui produise plus de points proches de 0 ?


---
class: my-one-page-font
# Echantillonnage préférentiel

Echantillonnage préférentiel : `\(g(x) = (1-a) \ x^{-a} \mathbb{1}_{[0,1]}(x)\)` et `\(\tilde{h}(x) = e^{-x}/ (1-a).\)`

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-73-1.png" width="360" style="display: block; margin: auto;" /&gt;
--


``` r
Z &lt;- X^(1/(1-a))
hZ &lt;- exp(-Z) / (1-a)
print(paste0("Estimation : ",mean(hZ),", variance : ",var(hZ)/n))
```

```
## [1] "Estimation : 1.51749207512399, variance : 0.000157397528531785"
```

On a diminué la variance par 100 pour une même taille d'échantillon.

--
Vraie valeur : 1.49365 (intégration numérique)


---
# Echantillonnage préférentiel

Avant, on intégrait `\(h(x) = e^{-x}x^{-a}\)` en utilisant la loi uniforme sur `\([0,1]\)`.

Maintenant, on intègre `\(\tilde{h}(x) = e^{-x}/(1-a)\)` en utilisant la loi de densité `\((1-a) \ x^{-a} \mathbb{1}_{[0,1]}(x)\)`.

&lt;img src="slides_25_files/figure-html/unnamed-chunk-75-1.png" width="864" style="display: block; margin: auto;" /&gt;

---
# Echantillonnage préférentiel

**Exemple 2** : calculer `\(\mathbb{P}(X&gt;10)\)` pour `\(X \sim \mathcal{E}(1)\)`.
--


``` r
1 - pexp(10) # vraie valeur calculée à l'aide de la fonction de répartition
mean(rexp(1000)&gt;10) # estimation par Monte Carlo naïf
```

```
## [1] 4.539993e-05
## [1] 0
```
--

L'estimateur est nul ... on n'a peut-être pas eu de chance sur ce tirage de 1000 ? Et si on ré-essayait ?


---
# Echantillonnage préférentiel

On tire 100 fois un échantillon de taille `\(n=1000\)` et on regarde ce que vaut l'estimateur par Monte Carlo sur chacun de ces 100 tirages.


``` r
repet_1000 &lt;- sapply(1:100,FUN = function(i){mean(rexp(1000)&gt;10)})
```

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-78-1.png" width="288" style="display: block; margin: auto;" /&gt;
&amp;rarr; l'estimateur vaut presque tout le temps 0 (96 fois sur 100), le reste du temps il vaut 0.001 (dans ces 4 cas, cela veut dire qu'une seule observation sur les 1000 du tirage était plus grande que 10).

---
# Echantillonnage préférentiel


Que se passe t-il si on augmente la taille des échantillons ?


``` r
repet_1000 &lt;- sapply(1:100,FUN = function(i){mean(rexp(1000)&gt;10)})
repet_10000 &lt;- sapply(1:100,FUN = function(i){mean(rexp(10000)&gt;10)})
repet_100000 &lt;- sapply(1:100,FUN = function(i){mean(rexp(100000)&gt;10)})
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-80-1.png" width="864" /&gt;

&amp;rarr; on obtient des résultats "raisonnables" quand `\(n=100 000\)`, mais la variance reste très élevée.


---
# Echantillonnage préférentiel

En prenant comme loi instrumentale `\(\mathcal{E}(1/10)\)`, on peut ré-écrire :

`$$\mathbb{P}(X&gt;10) =\mathbb{E}\left(\mathbf{1}_{Z&gt;10} \ 10 \ e^{-9Z/10}\right) \quad \text{où } Z \sim \mathcal{E}(1/10)$$`
En utilisant Monte-Carlo, on approche cette espérance à l'aide de la moyenne empirique d'un échantillon `\(Z_1,\dots,Z_n\)` de taille `\(n\)` de v.a. iid de loi exponentielle de paramètre 1/10.

`$$\hat{p} = \frac{1}{n} \sum_{i=1}^n 10 \ e^{-0.9 Z_i} \mathbf{1}_{Z_i &gt; 10}$$`

---
# Echantillonnage préférentiel

Code correspondant (pour un tirage, donc une estimation) :


``` r
Z &lt;- rexp(n,1/10)
w &lt;- 10*exp(-9*Z/10)  # ou plus généralement : dexp(Z,1)/dexp(Z,1/10)
mean(w*(Z&gt;10))
```

```
## [1] 5.706653e-05
```

--

On fait plusieurs tirages (plusieurs estimations de `\(p\)`) :



&lt;img src="slides_25_files/figure-html/unnamed-chunk-83-1.png" width="360" style="display: block; margin: auto;" /&gt;

C'est beaucoup mieux qu'avec la loi "naïve" !

---
# Echantillonnage préférentiel

Avec la loi `\(\mathcal{E}(1)\)` :


&lt;img src="slides_25_files/figure-html/unnamed-chunk-85-1.png" width="864" /&gt;
Avec la loi `\(\mathcal{E}(1/10)\)` :



&lt;img src="slides_25_files/figure-html/unnamed-chunk-87-1.png" width="864" /&gt;



---
# Choix de la loi instrumentale

- Calcul de la variance de `\(\tilde{h}_n\)`

--

- Choix optimal pour `\(g\)` &amp;rarr; celui qui minimise cette variance.


&lt;span style="color:#16A085"&gt;**fin du cours 8 (04/02/2025)**&lt;/span&gt;


---
name: c9
# Choix de la loi instrumentale

- Variance finie si le ratio `\(f/g\)` est borné (i.e. queues de distribution de `\(g\)` plus lourdes)

- La variance est optimale lorsque `\(g \propto |h|f\)` ... mais cette fonction est inconnue

--

- En pratique : choisir `\(g\)` telle que `\(|h|f/g\)` soit (presque) constant, et de variance finie.



---
class: my-one-page-font
# Choix de la loi instrumentale 

Que se passe t-il lorsque le ratio `\(f/g\)` n'est pas borné ?

--

 **Exemple** : on veut approcher `\(\int x^2 e^{-x^2/2} dx = \sqrt{2\pi} \ \mathbb{E}(X^2)\)` avec `\(X \sim \mathcal{N}(0,1)\)`. 

--

 1. en utilisant comme loi instrumentale la loi `\(\mathcal{N}(0,0.5^2)\)`.

&lt;img src="slides_25_files/figure-html/unnamed-chunk-88-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Choix de la loi instrumentale 

Code et approximation :


``` r
set.seed(10022025)
n &lt;- 1000
Z1 &lt;- rnorm(n,0,sd=0.5)
w1 &lt;- dnorm(Z1,0,1)/dnorm(Z1,0,0.5)
print(paste0("Estimation : ",sqrt(2*pi)*mean(Z1^2*w1),", variance : ",2*pi*var(Z1^2*w1)/n))
print(paste0("IC : [",paste0(round(sqrt(2*pi)*mean(Z1^2*w1)+qnorm(c(0.025,0.975))*sqrt(2*pi*var(Z1^2*w1)/n),3),collapse=","),"]"))
```

```
## [1] "Estimation : 1.76571757560692, variance : 0.0666274508629393"
## [1] "IC : [1.26,2.272]"
```

Vraie valeur : `\(\sqrt{2 \pi} =\)` 2.5066283.

---
# Choix de la loi instrumentale 

2. avec la loi instrumentale `\(\mathcal{N}(0,1.2^2)\)`

&lt;img src="slides_25_files/figure-html/unnamed-chunk-90-1.png" width="576" style="display: block; margin: auto;" /&gt;


---
# Choix de la loi instrumentale 

Code et approximation :


``` r
set.seed(10022025)
n &lt;- 1000
Z2 &lt;- rnorm(n,0,sd=1.2)
w2 &lt;- dnorm(Z2,0,1)/dnorm(Z2,0,1.2)
print(paste0("Estimation : ",sqrt(2*pi)*mean(Z2^2*w2),", variance : ",2*pi*var(Z2^2*w2)/n))
print(paste0("IC : [",paste0(round(sqrt(2*pi)*mean(Z2^2*w2)+qnorm(c(0.025,0.975))*sqrt(2*pi*var(Z2^2*w2)/n),3),collapse=","),"]"))
```

```
## [1] "Estimation : 2.58312378482309, variance : 0.00559442405726649"
## [1] "IC : [2.437,2.73]"
```

On a divisé la variance par 11.

Vraie valeur : `\(\sqrt{2 \pi} =\)` 2.5066283.

&amp;rarr; calcul de la loi Gaussienne optimale.


---
class: my-one-page-font
# Choix de la loi instrumentale

Si le ratio `\(f/g\)` n'est pas borné, certains poids d'importance peuvent être *trop élevés* ce qui donne trop de poids à certaines observations extrêmes.

&lt;img src="slides_25_files/figure-html/unnamed-chunk-92-1.png" width="576" style="display: block; margin: auto;" /&gt;

&lt;img src="slides_25_files/figure-html/unnamed-chunk-93-1.png" width="576" style="display: block; margin: auto;" /&gt;


---
# Version auto-normalisée

On peut définir une version *auto-normalisée* de l'estimateur (sous l'hypothèse que `\(g&gt;0\)` dès que `\(f&gt;0\)`):

`$$\bar{\mu}_n = \frac{\sum_{i=1}^n h(Z_i) f(Z_i)/g(Z_i)}{\sum_{i=1}^n f(Z_i)/g(Z_i)} = \frac{\sum_{i=1}^n w_i h(Z_i)}{\sum_{i=1}^n w_i}$$`
--

Sur notre exemple, cela donne :

&lt;img src="slides_25_files/figure-html/unnamed-chunk-94-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# Version auto-normalisée

En utilisant la version auto-normalisée, on obtient :
 - un estimateur **biaisé**
 - fortement consistant

Intérêts/avantages :
  - peut s'utiliser lorsque `\(f/g\)` est connue à une constante multiplicative près
  - une variance plus faible .red[**dans certains cas**]
  - permet également de *simuler* selon la loi `\(f\)`
  
Inconvénients :
  - hypothèse plus forte sur `\(g\)` (`\(g&gt;0\)` dès que `\(f&gt;0\)`, alors qu'en EP classique l'hypothèse `\(g&gt;0\)` dès que `\(hf&gt;0\)` suffit)
  - la variance est plus compliquée à calculer et ne peut pas être arbitrairement faible
  
  
---
# Version auto-normalisée

Simulation selon la loi `\(f\)` :

 &amp;rarr; en échantillonnant selon une loi **discrète** à support sur l'ensemble des `\(\{Z_1,\dots,Z_n\}\)`, et où la probabilité de tirer la valeur `\(Z_i\)` est `\(w_i /\sum_j w_j\)`.


``` r
Z &lt;- rnorm(10000,0,sd=1.5)
w2 &lt;- dnorm(Z,0,1)/dnorm(Z,0,1.5)
X &lt;- sample(Z, size = 2000, prob = w2/sum(w2))
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-96-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# Version auto-normalisée

.red[**Attention au biais introduit par la méthode**]

- Il faut une **taille d'échantillon suffisante** car la méthode est seulement **asymptotiquement sans biais**
- Pour échantillonner à l'aide des poids `\(w_i\)`, il faut tirer un échantillon plus petit que l'échantillon des `\((Z_1,\dots,Z_n)\)`
- On perd le caractère "i.i.d."

---
# Version auto-normalisée

**Exemple : ** on utilise les poids `\(w_i\)` obtenus après un EP de taille `\(n=1000\)` ou `\(n=10000\)` pour tirer un échantillon de taille 800 selon la loi `\(f\)`


``` r
Z &lt;- rnorm(1000,0,sd=1.5)
w_1000 &lt;- dnorm(Z,0,1)/dnorm(Z,0,1.5)
X_1000 &lt;- sample(Z, size = 800, prob = w_1000/sum(w_1000))

Z &lt;- rnorm(10000,0,sd=1.5)
w_10000 &lt;- dnorm(Z,0,1)/dnorm(Z,0,1.5)
X_10000 &lt;- sample(Z, size = 800, prob = w_10000/sum(w_10000))
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-98-1.png" width="720" style="display: block; margin: auto;" /&gt;


---
# Taille effective de l'échantillon 

- *effective sampling size* : pour identifier un mauvais choix de `\(g\)`
  - par exemple, on a `\(\mathbb{E}(f(Z)/g(Z)) = 1\)` pour `\(Z \sim g\)` &amp;rarr; on peut comparer la moyenne empirique des `\(w_i\)` à 1
  - critère ESS :
    `$$ESS = \frac{\left( \sum_{i=1} w_i \right)^2}{\sum_{i=1}^n w_i^2} = \frac{1}{\sum_{i=1}^n \bar{w}_i^2},$$`
      
      avec `\(\bar{w}_i = \frac{w_i}{\sum_{i=1}^n w_i}\)` le poids d'importance normalisé


Sur l'exemple précédent :

|    Loi    | Moy. empirique des poids |    ESS    |
|:---------:|:------------------------:|:---------:|
| N(0,0.5²) |        0.9763350         | 91.65902  |
| N(0,0.8²) |        0.9968692         | 859.86719 |
| N(0,1.2²) |        1.0096987         | 956.92246 |

---
class: inverse, middle, center

# 4. Réduction de variance

---
# Variables antithétiques

- **Objectif : ** approcher `\(\mu = \int h(x)f(x)dx\)`

- Permet de réduire la variance de l'estimateur en exploitant les propriétés de *symétrie* de la loi d'échantillonnage

- Elle s'utilise lorsque la loi considérée est stable par transformation, i.e. s'il existe une transformation `\(\nu\)` telle que si `\(X \sim f\)` alors `\(\nu(X) \sim f\)`.

- Quelques exemples de telles lois : uniformes, normales, student, (lois symétriques de façon générale), ...

&gt;  *Définition.* Soit `\(X_1,\dots,X_n\)` un échantillon i.i.d. de loi `\(f\)`. L'estimateur de `\(\mu\)` par la méthode des variables antithétiques est :
`$$\hat{\mu}_a = \frac{1}{n} \sum_{i=1}^n \frac{h(X_i) + h(\nu(X_i))}{2}$$`

---
# Variables antithétiques

Propriétés :
 - Sans biais
 - Fortement consistant
 - IC par TCL :
 
 `$$\sqrt{n} (\hat{\mu}_a - \mu) \longrightarrow \mathcal{N}(0,\sigma_a^2)$$`
 
Variance de l'estimateur :

--

`$$\text{Var}(\hat{\mu}_a) =  \frac{1}{2n} \text{Var}(h(X))(1+\rho),$$`
où `\(\rho = \text{Cov}(h(X),h(\nu(X)))/\text{Var}(h(X))\)`

&lt;span style="color:#16A085"&gt;**fin du cours 9 (10/02/2025)**&lt;/span&gt;


---
name: c10
# Variables antithétiques

Dans quel(s) cas cela fonctionne t-il ?

&gt; **Proposition :** si `\(h\)` est monotone et si `\(\nu\)` est décroissante, alors la méthode des variables antithétiques fournit un estimateur de variance plus faible qu'avec l'approche classique.

*Preuve*

---
# Variables antithétiques

**Exemple : ** estimer `\(\int_0^1 \frac{1}{1+x^2}dx\)`.


``` r
n &lt;- 1000
u &lt;- runif(n)
h &lt;- function(x){1/(1+x^2)}
est1 &lt;- mean(h(u))
var1 &lt;- mean((h(u)-est1)^2)/n
u1 &lt;- u[1:(n/2)]; u2 &lt;- 1-u1
v &lt;- c(u1,u2)
est2 &lt;- mean(h(v))
var2 &lt;- mean((0.5*(h(u1)+h(u2)) - est2)^2)/(n/2)
```


```
## [1] "Estimateur 1 (MC classique) : 0.780915 variance : 2.67175e-05"
```

```
## [1] "Estimateur 2 (variables antithétiques): 0.784972 variance : 4.041e-07"
```

Vraie valeur : `\(\arctan(1) =\)` 0.7853982.

---
# Variables de contrôle

L'objectif est d'utiliser une fonction auxiliaire dont on connaît l'espérance pour réduire la variance de l'estimateur.

&gt; **Définition : ** soit `\(h_0\)` une fonction t.q. `\(\mathbb{E}(h_0(X)) = m\)` est connue et de variance finie. Soit `\(c \in \mathbb{R}\)`. L'estimateur par variable de contrôle est :
`$$\hat{\mu}_c = \frac{1}{n} \sum_{i=1}^n [h(X_i) - c(h_0(X_i) - m)]$$`

Propriétés :
 - Sans biais
 - fortement consistant
 - IC par TCL :
  `$$\sqrt{n} (\hat{\mu}_c - \mu) \longrightarrow \mathcal{N}(0,\sigma_c^2)$$`

---
# Variables de contrôle

Dans quel(s) cas cela fonctionne t-il ?

&gt; **Proposition : ** l'estimateur optimal (au sens de la variance) est obtenu pour `\(c^* = \frac{\text{Cov}(h(X),h_0(X))}{\text{Var}(h_0(X))}\)`


``` r
n &lt;- 1000
X &lt;- rnorm(n)
hX &lt;- X&gt;2
p1 &lt;- mean(hX)
var1 &lt;- var(hX)/n
h0X &lt;- X&gt;0
copt &lt;- 2*(1-pnorm(2))
p2 &lt;- mean(hX - copt*(h0X-0.5))
var2 &lt;- mean((hX - copt*(h0X-0.5) - p2)^2)/n
```


```
## [1] "Estimateur 1 (MC classique) : 0.022 variance : 2.15375e-05"
```

```
## [1] "Estimateur 2 (variable de contrôle): 0.023502 variance : 2.09642e-05"
```

Vraie valeur : 0.0227501 et `\(c^* =\)` 0.0455003.

---
# Variables de contrôle

 - &lt;span style="color:red"&gt;**En pratique le calcul de `\(c^*\)` est impossible**&lt;/span&gt;
 - On peut l'estimer sur un premier échantillon de taille réduite (compromis entre les simulations supplémentaires nécessaires pour estimer `\(c^*\)` et le gain en variance)


``` r
n &lt;- 300
X &lt;- rnorm(n)
hX &lt;- X&gt;2
h0X &lt;- X&gt;0
copt_hat &lt;- cov(hX,h0X)/var(h0X)
n &lt;- 1000
X &lt;- rnorm(n)
hX &lt;- X&gt;2
h0X &lt;- X&gt;0
p2b &lt;- mean(hX - copt*(h0X-0.5))
var2b &lt;- mean((hX - copt*(h0X-0.5) - p2)^2)/n
```

Approximation de `\(c^*\)` : 0.0363636.


```
## [1] "Estimateur : 0.022865 variance : 2.09942e-05"
```

&lt;span style="color:#16A085"&gt;**fin du cours 10 (11/02/2025)**&lt;/span&gt;



---
name: c11
class: inverse, middle, center

# 5. Chaînes de Markov

---
# Introduction

 - Quelques éléments théoriques pour comprendre les algos MCMC

 - Une chaîne de Markov est une séquence de variables aléatoires qui évolue avec le temps, et dont la probabilité de transition ne dépend que de la valeur de la chaîne à l'instant présent

 - chaîne à espace d'états discret ou continu, à temps discret ou continu

 &amp;rarr; on va se concentrer sur le cas espace d'états continu et temps discret


---
# Introduction

Pourquoi s'intéresse t-on aux chaînes de Markov ?

 - pour générer des variables aléatoires *dépendantes* selon une chaîne de Markov convergente dont la loi stationnaire est la loi qui nous intéresse

 - le théorème ergodique nous permet alors d'utiliser cet échantillon dépendant pour approcher les mêmes quantités qu'avec le MC classique

---
# Introduction


Différence avec les méthodes de Monte Carlo : la façon dont on explore l'espace.

Exemple avec l'approximation du nombre `\(\pi\)`.
--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-106-1.png" width="750px" style="display: block; margin: auto;" /&gt;


---
class: my-one-page-font
# Noyau de transition

 - chaîne de Markov `\(X_1, X_2, \dots, X_n\)` de noyau de transition `\(K\)` :
 `$$X_n | X_{n-1}, X_{n-2}, \dots, X_2, X_1 \sim K(X_{n-1},X_{n})$$`

--

 - chaîne homogène en temps si `\(\mathbb{P}(X_n \in A | X_{n-1} = x) = \mathbb{P}(X_1 \in A | X_0 = x)\)`

--

 - exemple : marche aléatoire simple
 `$$X_n = X_{n-1} + \varepsilon_n, \quad \varepsilon \sim \mathcal{N}(0,1)$$`

 le noyau de transition `\(K(X_{n-1},X_n)\)` est celui de la loi `\(\mathcal{N}(X_{n-1},1)\)`.
&lt;img src="slides_25_files/figure-html/unnamed-chunk-107-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Noyau de transition

 - Propriété : `\(\forall n &gt; 1, \forall x \in E, \forall A \in \mathcal{E}, \quad K^n(x,A) := \int_E K^{n-1}(y,A) K(x,dy)\)`

 &amp;rarr; pour passer de l'état `\(x\)` à l'ensemble `\(A\)` en `\(n\)` étapes, on passe d'abord de `\(x\)` à `\(y\)` en une étape, puis de `\(y\)` à `\(A\)` en `\(n-1\)` étapes

 - Plus généralement, équation de Chapman-Kolmogorov :

 `\(K^{n+m}(x,A) := \int_E K^{m}(y,A) K^n(x,dy)\)`

 &amp;rarr; pour passer de `\(x\)` à `\(A\)` en `\(n+m\)` étapes, il faut passer par un état intermédiaire `\(y\)` à l'étape `\(n\)`

---
# Temps d'arrêt et nombre de passages

 - pour un ensemble `\(A\)`, on définit le *temps d'arrêt* en `\(A\)` par :

 `\(\tau_A = \inf \{ n | X_n \in A \}\)`
 &amp;rarr; c'est le premier temps d'atteinte de l'ensemble `\(A\)`
 
&lt;img src="slides_25_files/figure-html/unnamed-chunk-108-1.png" width="360" style="display: block; margin: auto;" /&gt;
 - de même on définit le *nombre de passages* en `\(A\)` par :
  `$$\eta_A = \sum_{n=1}^{+\infty} \mathbb{1}_{X_n \in A}$$`

---
# Mesure invariante

`\(\pi\)` est une mesure de probabilité **invariante** pour la chaîne de noyau `\(K\)` si
 `$$\forall B \in \mathcal{E}, \pi(B) = \int_E K(x,B) \pi(dx)$$`

 - exemple : `\(X_n = \rho X_{n-1} + \varepsilon_n\)`, avec `\(\varepsilon \sim \mathcal{N}(0,1)\)`

--


``` r
rho &lt;- 0.75; X &lt;- rep(0,10000)
for (i in 1:10000){
  Xold &lt;- ifelse(i==1,rnorm(1,0,1/(1-0.75^2)),X[i-1])
  X[i] &lt;- rho*Xold + rnorm(1)}
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-110-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Irréductibilité

 - mesure la sensibilité de la chaîne aux conditions initiales

 - très important en pratique pour les algorithmes MCMC car apporte une garantie de convergence quel que soit le point de départ

 - dans le cas espace d'états discret, la chaîne est dite irréductible si tous les états communiquent

 - définition équivalente : `\(\forall x, \forall A\)` t.q. `\(\mu(A)&gt;0\)`, `\(\mathbb{E}_x(\eta_A) &gt; 0\)`

 - &lt;span style="color:red"&gt;condition suffisante : `\(K(x,\cdot) &gt; 0\)`&lt;/span&gt;

---
# Apériodicité

 - Irréductible : tout ensemble de mesure non nulle peut être atteint à partir de n'importe quel point de `\(E\)` en un temps fini

--

 - Mais la chaîne peut rester bloquée dans un cycle

--

 &amp;rarr; apériodicité

--

`\(\Rightarrow\)` irréductibilité et apériodicité assurent que la chaîne peut aller de n'importe quel point `\(x\)` à n'importe quel point `\(y\)` **en une seule itération**

---
# Récurrence

 - Déplacement possible de `\(x\)` à `\(y\)` en une étape, pour tous `\(x\)` et `\(y\)`

--

 - Mais ces déplacements doivent être possibles **une infinité de fois**

 &amp;rarr; récurrence

---
# Résumé

 - Si une chaîne de Markov est récurrente et admet une loi stationnaire, cette loi est également la loi limite de la chaîne

 - C'est ce qu'on appelle l'**ergodicité**

 - Alors, si on peut générer une chaîne de Markov dont la loi stationnaire est la loi cible, on obtient un échantillon .red[**(non i.i.d.)**] selon cette loi

 &amp;rarr; théorème ergodique
 
 
---
class: inverse, middle, center

# 6. Algorithmes MCMC

---
# Introduction

**Objectif** : évaluer `\(\int h(x) f(x) dx\)`

 - Idée : construire une chaîne de Markov ergodique, admettant pour loi stationnaire la loi cible `\(f\)`

 - Utiliser les réalisations de la chaîne pour approcher l'intégrale par une moyenne empirique

 - Intérêts :
  - réduction de variance
  - plus facile à mettre en place
  - plus adapté en grande dimension

 - Inconvénients :
  - vitesse de convergence qui peut être lente
  - forte corrélation possible dans l'échantillon

---
# Algorithme de Metropolis-Hastings

 - Article fondateur en 1953 par N Metropolis, A Rosenbluth, M Rosenbluth, A Teller, E Teller pour des distributions apparaissant en physique nucléaire

&lt;img src="slides_25_files/figure-html/unnamed-chunk-111-1.png" width="800px" style="display: block; margin: auto;" /&gt;

 - Généralisé en 1970 par W Hastings pour des distributions quelconques

&lt;img src="slides_25_files/figure-html/unnamed-chunk-112-1.png" width="150px" style="display: block; margin: auto;" /&gt;
---
# Algorithme de  Metropolis-Hastings

Construction d'une chaîne de Markov selon l'algorithme suivant :

 1. **initialisation** : `\(X_0\)`
 2. **pour** `\(n=1, \dots, N\)` :
  - `\(Y_n \sim q(\cdot | X_{n-1})\)` où `\(q\)` est la *loi de proposition*
  - `\(\begin{equation}X_n = \begin{cases}Y_n &amp; \text{avec probabilité } \alpha(X_{n-1},Y_n) \\ X_{n-1} &amp; \text{avec probabilité } 1-\alpha(X_{n-1},Y_n) \end{cases}\end{equation}\)`

  où :
  $$\alpha(x,y) = \min \left(1, \frac{f(y) q(x | y)}{f(x) q(y | x)} \right) $$


RQ : fonctionne si on connaît `\(f\)` et/ou `\(q\)` à une constante près.

---
# Algorithme de Metropolis-Hastings

**Exemple** : loi cible `\(f\)` loi `\(\mathrm{Beta}(2.5,8)\)` et loi de proposition `\(q\)` la loi `\(\mathcal{U}([0,1])\)`


``` r
a=2.5; b=8
N &lt;- 5000
X &lt;- rep(0,N); X[1]=runif(1) # initialisation
for (i in 2:N){
  Y &lt;- runif(1) # candidat généré selon la loi q
  alpha &lt;- dbeta(Y,a,b)/dbeta(X[i-1],a,b)
  U &lt;- runif(1)
  X[i] &lt;- ifelse(U&lt;alpha,Y,X[i-1])}
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-114-1.png" width="576" style="display: block; margin: auto;" /&gt;

&lt;span style="color:#16A085"&gt;**fin du cours 11 (24/02/2025)**&lt;/span&gt;

---
name: c12
# Algorithme de Metropolis-Hastings

Construction d'une chaîne de Markov (**dans** `\(\mathbb{R}^p\)`) selon l'algorithme suivant :

 1. **initialisation** : `\(X_0\)`
 2. **pour** `\(n=1, \dots, N\)` :
  - `\(Y_n \sim q(\cdot | X_{n-1})\)` où `\(q\)` est la *loi de proposition*

  - `\(\begin{equation}X_n = \begin{cases}Y_n &amp; \text{avec probabilité } \alpha(X_{n-1},Y_n) \\ X_{n-1} &amp; \text{avec probabilité } 1-\alpha(X_{n-1},Y_n) \end{cases}\end{equation}\)`

  où : `\(\alpha(X_{n-1},Y_n) = \min \left(1, \frac{f(Y_n)}{f(X_{n-1})}\frac{ q(X_{n-1} | Y_n)}{q(Y_n | X_{n-1})} \right)\)`


Toutes choses égales par ailleurs, `\(\alpha(X_{n-1},Y_n)\)` augmente :
- avec le ratio `\(\frac{f(Y_n)}{f(X_{n-1})}\)`,
- avec le ratio `\(\frac{q(X_{n-1} | Y_n)}{q(Y_n | X_{n-1})}\)`
- &lt;span style="color:red"&gt;**un candidat t.q. `\(\frac{f(Y_n)}{q(Y_n | X_{n-1})} &gt; \frac{f(X_{n-1})}{q(X_{n-1} | Y_n)}\)` est toujours accepté**&lt;/span&gt;

---
# Algorithme de Metropolis-Hastings

**Exemple** : loi cible `\(f\)` loi `\(\mathrm{Beta}(2.5,8)\)` et loi de proposition `\(q\)` la loi `\(\mathcal{U}([0.8X_{n-1},1.2X_{n-1}])\)`

--


``` r
set.seed(19022024)
a=2.5; b=8
N &lt;- 5000
X &lt;- rep(0,N); X[1] &lt;- runif(1)
for (i in 2:10){
    Y &lt;- runif(1,0.8*X[i-1],1.2*X[i-1]) # candidat généré selon la loi q
    alpha &lt;- (dbeta(Y,a,b)/dbeta(X[i-1],a,b)) *
      (dunif(X[i-1],0.8*Y,1.2*Y)/dunif(Y,0.8*X[i-1],1.2*X[i-1]))
    U &lt;- runif(1)
    X[i] &lt;- ifelse(U&lt;alpha,Y,X[i-1])}
print(X[1:10])
```

```
##  [1] 0.7837793 0.7837793 0.8002693 0.7793696 0.7378524 0.6250122 0.6250122
##  [8] 0.6016766 0.5871069 0.5538738
```

---
# Algorithme de Metropolis-Hastings

Etat courant : `\(X_{n-1} =\)` 0.5539, loi instrumentale : `\(\mathcal{U}\)`([0.44312,0.66468]).
--
&lt;img src="slides_25_files/figure-html/unnamed-chunk-116-1.png" width="432" style="display: block; margin: auto;" /&gt;

--
Candidat à l'itération `\(n\)` : `\(Y_n\)` = 0.6417618


---
# Algorithme de Metropolis-Hastings

Etat courant : `\(X_{n-1} =\)` 0.5539, loi instrumentale : `\(\mathcal{U}\)`([0.44312,0.66468]).
&lt;img src="slides_25_files/figure-html/unnamed-chunk-117-1.png" width="432" style="display: block; margin: auto;" /&gt;
Candidat à l'itération `\(n\)` : `\(Y_n\)` = 0.6417618

`\(\frac{f(Y_n)}{q(Y_n | X_{n-1})}\)` = 0.014588, `\(\frac{f(X_{n-1})}{q(X_{n-1} | Y_{n})}\)` = 0.062954, `\(\frac{f(Y_n)}{f(X_{n-1})}\)` = 0.268499 et `\(\frac{q(X_{n-1} | Y_n)}{q(Y_n | X_{n-1})}\)` = 0.863052

`\(\alpha(X_{n-1},Y_n)\)` = 0.2317289

on génère `\(U \sim \mathcal{U}([0,1])\)` : 0.2655087


---
# Algorithme de Metropolis-Hastings

Preuve de convergence :
--

 1. noyau de transition de la chaîne
--

 2. condition suffisante d'existence d'une loi stationnaire : *detailed-balanced condition*
--
 
 3. condition suffisante pour l'apériodicité
--
 
 4. condition suffisante pour l'irréductibilité

--

Choix de la loi `\(q\)` : deux cas particuliers
 - loi instrumentale indépendante de `\(X_{n-1}\)`
 - loi instrumentale symétrique 

---
# MH à loi instrumentale indépendante

Cas où `\(q\)` est indépendant de `\(X_{n-1}\)` &amp;rarr; `\(q(x | y) = q(x)\)`

 - la loi instrumentale ne dépend pas de l'état courant de la chaîne.
 - voir l'exemple de la slide 141 (loi cible `\(\text{Beta}(2.5,8)\)` et loi de proposition `\(q\)` la loi `\(\mathcal{U}([0,1])\)`)
 - la probabilité d'acceptation s'écrit : `\(\alpha(X_{n-1},Y_n) = \min \left(1, \frac{f(Y_n)}{f(X_{n-1})}\frac{ q(X_{n-1})}{q(Y_n)} \right)\)`

 - s'il existe `\(M\)` telle que `\(f\leq Mq\)` alors la chaîne est *uniformément ergodique* (propriété très forte)
 - comparaison avec l'algorithme d'acceptation-rejet &amp;rarr; voir TD

---
# MH à loi instrumentale symétrique

Cas où `\(q\)` est symétrique en `\(x\)` et `\(y\)` &amp;rarr; `\(q(y | x) = q(x | y)\)`

 - souvent on a `\(q(y | x) = q(|y - x|)\)`
 &amp;rarr; exemple de la marche aléatoire symétrique
 
 - voir l'exemple de la slide 143 (loi cible `\(\text{Beta}(2.5,8)\)` et loi de proposition `\(q\)` la loi `\(\mathcal{U}([0.8X_{n-1},1.2X_{n-1}])\)`)
 - la probabilité d'acceptation se simplifie : `\(\alpha(X_{n-1},Y_n) = \min \left(1, \frac{f(Y_n)}{f(X_{n-1})}\right)\)`

 - si `\(\text{supp}(f) \subset \text{supp}(q)\)` alors la chaîne est ergodique de mesure invariante `\(f\)`

 - RQ : si `\(f\)` est à support dans `\(\mathbb{R}\)`, la chaîne ne pourra jamais être uniformément ergodique

 - .red[**attention au choix de la variance de la marche aléatoire**]

---
# MH à marche aléatoire (MH-MA)

**Exemple** : loi cible `\(f\)` la loi normale centrée réduite, et loi instrumentale `\(q\)` la loi normale centrée en `\(X_{n-1}\)` et de variance `\(\sigma^2\)`, pour différentes valeurs de `\(\sigma\)`.


``` r
X1 &lt;- X2 &lt;- X3 &lt;- rep(0,2000);
for (i in 2:2000){
  # chaine 1
  Y &lt;- rnorm(1,X1[i-1],0.1)
  alpha &lt;- dnorm(Y)/dnorm(X1[i-1])
  X1[i] &lt;- ifelse(runif(1)&lt;alpha,Y,X1[i-1])
  # chaine 2
  Y &lt;- rnorm(1,X2[i-1],2)
  alpha &lt;- dnorm(Y)/dnorm(X2[i-1])
  X2[i] &lt;- ifelse(runif(1)&lt;alpha,Y,X2[i-1])
  # chaine 3
  Y &lt;- rnorm(1,X3[i-1],15)
  alpha &lt;- dnorm(Y)/dnorm(X3[i-1])
  X3[i] &lt;- ifelse(runif(1)&lt;alpha,Y,X3[i-1])
}
```


---
# MH à marche aléatoire (MH-MA)


&lt;img src="slides_25_files/figure-html/unnamed-chunk-119-1.png" width="1080" style="display: block; margin: auto;" /&gt;

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-120-1.png" width="1080" style="display: block; margin: auto;" /&gt;

---
# MH à marche aléatoire (MH-MA)

Pour diagnostiquer une mauvaise exploration :
- calculer le **taux d'acceptation** (la proportion de candidats ayant été acceptés)
   - ne doit être ni trop haut, ni trop bas
   - sur l'exemple précédent : 0.969, 0.505 et 0.0875 pour les chaînes 1, 2 et 3
   - recommandation pratique : &lt;span style="color:#16A085"&gt; `\(\approx\)` 0.45 en dim 1 et 2, `\(\approx\)` 0.25 si `\(p&gt;2\)`&lt;/span&gt;
--

- étudier l'**autocorrélation** des réalisations de la chaîne (fonction `acf()` sous R, `plot_acf()` du module `statsmodels.graphics.tsaplots` sous Python)

&lt;img src="slides_25_files/figure-html/unnamed-chunk-121-1.png" width="972" style="display: block; margin: auto;" /&gt;

&lt;span style="color:#16A085"&gt;**fin du cours 12 (25/02/2025)**&lt;/span&gt;


---
name: c13

# De MH à l'échantillonneur de Gibbs

 - Algorithme générique qui fonctionne pour une grande classe de lois `\(f\)`
 - Le choix de `\(q\)` ne requiert pas une grande connaissance de `\(f\)`
 - On peut améliorer l'efficacité des algorithmes (e.g. la convergence) en exploitant les caractéristiques de `\(f\)`

 &amp;rarr; algorithmes utilisant la forme de `\(f\)` et sa géométrie

---
# Slice sampler

&gt; **Théorème** : simuler `\(X\)` selon la loi `\(f\)` est équivalent à simuler le couple `\((X,U)\)` selon la loi uniforme sur l'ensemble `\(\mathcal{D} = \{(x,u) : 0 \leq u \leq f(x)\}\)`

*Preuve*

--

- Pour simuler `\(X\)` selon la loi `\(f\)`, on peut alors simuler un point `\((X,U)\)` uniformément **sous le graphe** de la densité `\(f\)` et garder uniquement l'abscisse des points (la loi marginale de `\(X\)`)

- C'est déjà ce que l'on fait dans la méthode d'acceptation-rejet en simulant dans une région **plus grande** et en ne gardant que les points **sous la courbe**

- L'algorithme du slice sampler permet d'atteindre le même objectif mais de façon plus efficace en proposant un déplacement de type marche aléatoire sur l'ensemble `\(\mathcal{D}\)`.

---
# Slice sampler

Exemple de la loi `\(\text{Beta}(a,b)\)`. Avec l'acceptation-rejet (voir TD) :
 - on simule `\(Y \sim \mathcal{U}([0,1])\)`
 - puis `\(U \sim \mathcal{U}([0,M_{a,b}])\)`
 - et on garde les couples `\((Y,U)\)` tels que `\(U &lt; f(Y)\)`
 
&lt;img src="slides_25_files/figure-html/unnamed-chunk-122-1.png" width="504" style="display: block; margin: auto;" /&gt;

&amp;rarr; on perd `\(1-1/M\)` soit environ 59.3% des points ...

---
# Slice sampler

En pratique :
  1. **initialisation** : `\(X_0=x_0\)`
  2. **pour** `\(n=1,\dots,N\)`
    - `\(U_n \sim \mathcal{U}([0,f(x_{n-1})])\)`
    - `\(X_n \sim \mathcal{U}(\mathcal{D}_n)\)` où
    `\(\mathcal{D}_n = \{x : f(x) \geq u_n\}\)`

&lt;img src="slides_25_files/figure-html/unnamed-chunk-123-1.png" width="500px" style="display: block; margin: auto;" /&gt;
*(source : Andrieu et al. 2003)*


&lt;span style="color:red"&gt;**RQ. : on peut utiliser l'algorithme si `\(f\)` est connue à une constante multiplicative près**&lt;/span&gt;


---
# Slice sampler

**Exemple** : on veut simuler selon la loi `\(\mathcal{N}(0,1)\)`, de densité `\(f(x) \propto e^{-x^2/2}\)`

 &amp;rarr; à l'itération `\(n\)`, on a `\(X_{n-1}=x_{n-1}\)` :
  - on génère `\(U_n \sim \mathcal{U}([0,\exp(-x_{n-1}^2/2)])\)`
  - on détermine l'ensemble `\(\mathcal{D}_n = \{x : e^{-x^2/2} &gt; u_n\}\)`
--

  - on simule `\(X_n \sim \mathcal{U}([-\sqrt{-2 \log(u_n)} ; \sqrt{-2 \log(u_n)}])\)`

--
&lt;img src="slides_25_files/figure-html/unnamed-chunk-124-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Slice sampler

**Exemple** : on veut simuler selon la loi `\(\mathcal{N}(0,1)\)`, de densité `\(f(x) \propto e^{-x^2/2}\)`

 &amp;rarr; à l'itération `\(n\)`, on a `\(X_{n-1}=x_{n-1}\)` :
  - on génère `\(U_n \sim \mathcal{U}([0,\exp(-x_{n-1}^2/2)])\)`
  - on détermine l'ensemble `\(\mathcal{D}_n = \{x : e^{-x^2/2} &gt; u_n\}\)`
  - on simule `\(X_n \sim \mathcal{U}([-\sqrt{-2 \log(u_n)} ; \sqrt{-2 \log(u_n)}])\)`


&lt;img src="slides_25_files/figure-html/unnamed-chunk-125-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
# Slice sampler

**Exemple** : on veut simuler selon la loi `\(\mathcal{N}(0,1)\)`, de densité `\(f(x) \propto e^{-x^2/2}\)`

 &amp;rarr; à l'itération `\(n\)`, on a `\(X_{n-1}=x_{n-1}\)` :
  - on génère `\(U_n \sim \mathcal{U}([0,\exp(-x_{n-1}^2/2)])\)`
  - on détermine l'ensemble `\(\mathcal{D}_n = \{x : e^{-x^2/2} &gt; u_n\}\)`
  - on simule `\(X_n \sim \mathcal{U}([-\sqrt{-2 \log(u_n)} ; \sqrt{-2 \log(u_n)}])\)`


&lt;img src="slides_25_files/figure-html/unnamed-chunk-126-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Slice sampler

**Exemple** : on veut simuler selon la loi `\(\mathcal{N}(0,1)\)`, de densité `\(f(x) \propto e^{-x^2/2}\)`

 &amp;rarr; à l'itération `\(n\)`, on a `\(X_{n-1}=x_{n-1}\)` :
  - on génère `\(U_n \sim \mathcal{U}([0,\exp(-x_{n-1}^2/2)])\)`
  - on détermine l'ensemble `\(\mathcal{D}_n = \{x : e^{-x^2/2} &gt; u_n\}\)`
  - on simule `\(X_n \sim \mathcal{U}([-\sqrt{-2 \log(u_n)} ; \sqrt{-2 \log(u_n)}])\)`

&lt;img src="slides_25_files/figure-html/unnamed-chunk-127-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
# Slice sampler

&lt;img src="slides_25_files/figure-html/unnamed-chunk-128-1.png" width="500px" style="display: block; margin: auto;" /&gt;
.center[*(source : Bayesian Statistics Group)*]

.pull-left[
.green[**Avantages**]
- tirages selon des lois uniformes
- pas d'hypothèses spécifiques sur `\(f\)`
- `\(f\)` peut être connue à une constante près
]
.pull-right[
.red[**Inconvénients**]
- calcul de `\(\mathcal{D}_n\)` peut être délicat
- extensions possibles dans ce cas qui peuvent être plus lourdes à implémenter
]

---
# Slice sampler

Exemple avec la loi `\(\text{Beta}(2,5)\)`, on a `\(\mathcal{D_n} = \{(x,u) : C x (1-x)^4 &gt; u_n \}\)`.



``` r
set.seed(0)
X &lt;- runif(1)
U &lt;- runif(1,0,dbeta(X,5,2))
*Dn &lt;- rootSolve::uniroot.all(function(x){dbeta(x,5,2)-U},lower=0,upper=1)
Dn
```

```
## [1] 0.4177093 0.9808084
```
&lt;img src="slides_25_files/figure-html/unnamed-chunk-130-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Slice sampler


``` r
n &lt;- 1000
X &lt;- runif(1)
for (i in 2:n){
 U &lt;- runif(1,0,dbeta(X[i-1],5,2))
 Dn &lt;- uniroot.all(function(x){dbeta(x,5,2)-U[i]},lower=0,upper=1) 
 X &lt;- c(X,runif(1,Dn[1],Dn[2]))
}
```


&lt;img src="slides_25_files/figure-html/unnamed-chunk-132-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Echantillonneur de Gibbs

Idée générale : en dimension `\(p\)` &gt; 1, simuler chaque coordonnée l'une après l'autre

--

**Cas `\(p=2\)`**

`\((X,Y) \in \mathbb{R}^2\)`
  1. **initialisation** : `\((X_0,Y_0) = (x_0,y_0)\)`
  2. **pour** `\(n=1, \dots, N\)` :
   - `\(X_n \sim f_{X|Y}(\cdot | y_{n-1})\)`
   - `\(Y_n \sim f_{Y|X}(\cdot | x_{n})\)`

--

**Exemple** : `\(Z=(X,Y) \sim \mathcal{N}\left(\begin{pmatrix}0 \\0 \end{pmatrix}, \begin{pmatrix}1 &amp; \rho \\ \rho &amp; 1 \end{pmatrix}\right)\)`

---
# Echantillonneur de Gibbs


``` r
n &lt;- 10000; rho &lt;- 0.8; X &lt;- Y &lt;- rep(0,n);
for (i in 2:n){
  # mise à jour de la 1ère coordonnée
  X[i] &lt;- rnorm(1,rho*Y[i-1],sqrt(1-rho^2))
  # mise à jour de la 2ème coordonnée
  Y[i] &lt;- rnorm(1,rho*X[i],sqrt(1-rho^2)) }
```

.pull-left[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-134-1.png" width="360" /&gt;
]
.pull-right[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-135-1.png" width="432" /&gt;
]

---
# Echantillonneur de Gibbs


``` r
n &lt;- 10000; rho &lt;- 0.8; X &lt;- Y &lt;- rep(0,n);
for (i in 2:n){
  # mise à jour de la 1ère coordonnée
  X[i] &lt;- rnorm(1,rho*Y[i-1],sqrt(1-rho^2))
  # mise à jour de la 2ème coordonnée
  Y[i] &lt;- rnorm(1,rho*X[i],sqrt(1-rho^2)) }
```

.pull-left[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-137-1.png" width="360" /&gt;
]
.pull-right[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-138-1.png" width="360" /&gt;
]

---
# Echantillonneur de Gibbs

En pratique, comment se passe l'itération `\(n\)` ?

&lt;ol&gt;
&lt;li&gt; on part du point `\((X_{n-1},Y_{n-1})\)`
&lt;/ol&gt;

&lt;img src="slides_25_files/figure-html/unnamed-chunk-139-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Echantillonneur de Gibbs

En pratique, comment se passe l'itération `\(n\)` ?

&lt;ol start="2"&gt;
&lt;li&gt; on génère la 1ère coordonnée conditionnellement à `\(Y_{n-1}=y_{n-1}\)`
&lt;/ol&gt;

&lt;img src="slides_25_files/figure-html/unnamed-chunk-140-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Echantillonneur de Gibbs

En pratique, comment se passe l'itération `\(n\)` ?

&lt;ol start="3"&gt;
&lt;li&gt; on génère la 2ème coordonnée conditionnellement à `\(X_n=x_n\)`
&lt;/ol&gt;

&lt;img src="slides_25_files/figure-html/unnamed-chunk-141-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Echantillonneur de Gibbs

&amp;rarr; on ne fait que des mouvements *parallèles aux axes*

&lt;img src="slides_25_files/figure-html/unnamed-chunk-142-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Echantillonneur de Gibbs

 - A un intérêt lorsque la loi jointe `\(f_{X,Y}\)` ou les lois marginales `\(f_X\)` ou `\(f_Y\)` ne peuvent pas être calculées explicitement

--

 - La chaîne `\((X_t,Y_t)_t\)` est stationnaire de loi `\(f_{X,Y}\)`, de même que `\((X_t)_t\)` et `\((Y_t)_t\)` sont stationnaires de loi `\(f_X\)` et `\(f_Y\)` resp.

--

 - Simuler selon les lois conditionnelles **suffit** pour obtenir un échantillon selon la loi jointe (théorème de Hammersley-Clifford)
 - .blue[**Question :** Est-ce le cas si on remplace 'loi conditionnelle' par 'loi marginale' ?]

--

 - C'est un cas particulier de l'algorithme de Metropolis-Hastings

---
# Echantillonneur de Gibbs

**Cas général `\(p&gt;2\)`**

`\((X_1,\dots,X_p) \in \mathbb{R}^p\)` de loi jointe `\(f\)`
  1. **initialisation** : `\((X_{0,1},\dots,X_{0,p}) = (x_{0,1},\dots,x_{0,p})\)`
  2. **pour** `\(n=1, \dots, N\)` :
   - `\(X_{n,1} \sim f_1(\cdot | x_{n-1,2},\dots,x_{n-1,p})\)`
   - `\(X_{n,2} \sim f_2(\cdot | x_{n,1},x_{n-1,3},\dots,x_{n-1,p})\)`
   - `\(\dots\)`
   - `\(X_{n,p} \sim f_p(\cdot | x_{n,1},\dots,x_{n,p-1})\)`

- Les densités `\(f_1,\dots,f_p\)` sont appelées *lois conditionnelles complètes*.
- On ne fait que des simulations en dimension 1

---
# Echantillonneur de Gibbs

Pourquoi ça marche ?

&gt; *Théorème de Hammersley-Clifford.* Si le support de la loi jointe est le produit cartésien des supports des lois marginales, alors :
`$$f(x_1,\dots,x_p) \propto \prod_{j=1}^p \frac{f_j(x_j | x_1,\dots,x_{j-1},z_{j+1},\dots,z_p)}{f_j(z_j | x_1,\dots,x_{j-1},z_{j+1},\dots,z_p)}$$`
pour tout vecteur `\((z_1,\dots,z_p)\)` dans le support de `\(f\)`.

&lt;/br&gt;
Propriétés de convergence :
 - Mesure invariante
 - Irréductibilité et récurrence
 - Apériodicité

---
# Condition de positivité

**Exemple :** loi cible `\(f(x,y) = \frac{1}{2} \left(\mathbb{1}_{[-1,0]\times[-1,0]}(x,y) + \mathbb{1}_{[0,1]\times[0,1]}(x,y)\right)\)`

--

&lt;img src="slides_25_files/figure-html/unnamed-chunk-143-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Condition de positivité

**Exemple :** loi cible `\(f(x,y) = \frac{1}{2} \left(\mathbb{1}_{[-1,0]\times[-1,0]}(x,y) + \mathbb{1}_{[0,1]\times[0,1]}(x,y)\right)\)`

&lt;img src="slides_25_files/figure-html/unnamed-chunk-144-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
class: my-one-page-font
# Variantes

 - Gibbs avec mise à jour aléatoire : à chaque itération `\(n\)`, on choisit aléatoirement la coordonnée à mettre à jour
 - Metropolis-within-Gibbs : si on ne sait pas simuler selon `\(f_k\)`, on peut remplacer par une étape de Metropolis-Hastings :
 
  **pour** `\(n=1, \dots, N\)` et la coordonnée `\(k\)` :
   - `\(Y_{n,k} \sim q_k(\cdot | x_{n,1},\dots,x_{n,k-1},x_{n-1,k},x_{n-1,k+1},\dots,x_{n-1,p})\)` 
   
   - on pose `\(X_{n,k} = Y_{n,k}\)` avec probabilité `\(\alpha_k(X_{n-1,k},Y_{n,k})\)` et `\(X_{n,k}=X_{n-1,k}\)` avec probabilité `\(1- \alpha_k(X_{n-1,k},Y_{n,k})\)`, avec :
   
    `$$\alpha_k(X_{n-1,k},Y_{n,k}) = \min\left[1,\frac{\frac{f_k(Y_{n,k} | X_{n,1},\dots,X_{n,k-1},X_{n-1,k+1},\dots,X_{n-1,p})}{q_k(Y_{nk,} | X_{n,1},\dots,X_{n,k-1},X_{n-1,k},X_{n-1,k+1},\dots,X_{n-1,p})}}{\frac{q_k(X_{n-1,k} | X_{n,1},\dots,X_{n,k-1},Y_{n,k},X_{n-1,k+1},\dots,X_{n-1,p})}{f_k(X_{n-1,k} | X_{n,1},\dots,X_{n,k-1},X_{n-1,k+1},\dots,X_{n-1,p})} } \right]$$`
    

&lt;span style="color:#16A085"&gt;**fin du cours 13 (04/03/2025)**&lt;/span&gt;

---
name: c14
# Résumé des épisodes précédents

.bold[Objectif :] estimer `\(\mu = \int h(x)f(x)dx\)` avec `\(f\)` densité de probabilité

--

**Méthode :** &lt;span style="color:orange"&gt; **obtenir des réalisations `\(X_1,\dots,X_n\)` selon la loi `\(f\)`**&lt;/span&gt; et &lt;span style="color:blue"&gt;**poser `\(\hat{\mu} = \frac{1}{n}\sum_{i=1}^n h(X_i)\)`**&lt;/span&gt;

--

&lt;span style="color:orange"&gt;**1. Obtenir des réalisations selon la loi `\(f\)`**&lt;/span&gt;

- *méthode 1* : simuler directement selon `\(f\)`

&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;

- *méthode 2* : utiliser une loi instrumentale `\(g\)`


---
# Résumé des épisodes précédents

.bold[Objectif :] estimer `\(\mu = \int h(x)f(x)dx\)` avec `\(f\)` densité de probabilité

**Méthode :** &lt;span style="color:orange"&gt; **obtenir des réalisations `\(X_1,\dots,X_n\)` selon la loi `\(f\)`**&lt;/span&gt; et &lt;span style="color:blue"&gt;**poser `\(\hat{\mu} = \frac{1}{n}\sum_{i=1}^n h(X_i)\)`**&lt;/span&gt;

&lt;span style="color:orange"&gt;**1. Obtenir des réalisations selon la loi `\(f\)`**&lt;/span&gt;

- *méthode 1* : simuler directement selon `\(f\)`
 - méthode de la fonction inverse
 - lien avec d'autres lois (e.g. loi conditionnelle, ...)
 - slice sampler
 - échantillonneur de Gibbs (en passant par les lois conditionnelles)

- *méthode 2* : utiliser une loi instrumentale `\(g\)`
 - acceptation-rejet
 - échantillonnage préférentiel avec ré-échantillonnage
 - algorithme de Metropolis-Hastings
 - Metropolis-within-Gibbs 

---
name: simu_f
# Résumé des épisodes précédents

.bold[Objectif :] estimer `\(\mu = \int h(x)f(x)dx\)` avec `\(f\)` densité de probabilité

**Méthode :** &lt;span style="color:orange"&gt; **obtenir des réalisations `\(X_1,\dots,X_n\)` selon la loi `\(f\)`**&lt;/span&gt; et &lt;span style="color:blue"&gt;**poser `\(\hat{\mu} = \frac{1}{n}\sum_{i=1}^n h(X_i)\)`**&lt;/span&gt;

&lt;span style="color:orange"&gt;**1. Obtenir des réalisations selon la loi `\(f\)`**&lt;/span&gt;

- *méthode 1* : simuler directement selon `\(f\)` &lt;span style="color:red"&gt;&amp;rarr; `\(f\)` **connue exactement**&lt;/span&gt;
 - méthode de la fonction inverse &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. i.i.d.** &lt;/span&gt;
 - lien avec d'autres lois (e.g. loi conditionnelle, ...) &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. i.i.d.** &lt;/span&gt;
 - slice sampler &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. MC** &lt;/span&gt;
 - échantillonneur de Gibbs &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. MC** &lt;/span&gt;

- *méthode 2* : utiliser une loi instrumentale `\(g\)` &lt;span style="color:red"&gt;&amp;rarr; `\(f\)` **connue à une constante près** &lt;/span&gt;
 - acceptation-rejet &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. i.i.d.** &lt;/span&gt;
 - échantillonnage préférentiel avec ré-échantillonnage &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. i.i.d.** &lt;/span&gt;
 - algorithme de Metropolis-Hastings &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. MC** &lt;/span&gt;
 - Metropolis-within-Gibbs &lt;span style="color:#16A085"&gt;&amp;rarr; **éch. MC** &lt;/span&gt;


---
# Résumé des épisodes précédents

.bold[Objectif :] estimer `\(\mu = \int h(x)f(x)dx\)` avec `\(f\)` densité de probabilité

**Méthode :** &lt;span style="color:orange"&gt; **obtenir des réalisations `\(X_1,\dots,X_n\)` selon la loi `\(f\)`**&lt;/span&gt; et &lt;span style="color:blue"&gt;**poser `\(\hat{\mu} = \frac{1}{n}\sum_{i=1}^n h(X_i)\)`**&lt;/span&gt;

&lt;span style="color:blue"&gt;**2. Poser `\(\hat{\mu} = \frac{1}{n}\sum_{i=1}^n h(X_i)\)` &lt;/span&gt; **

- quelle est la qualité de cette approximation ?
 - convergence
 - biais
 - **variance**
 - coût computationnel

- pour les échantillons de type chaîne de Markov :
 - convergence de la chaîne ?
 - exploration de l'espace ?
 - sensibilité aux conditions initiales ?

---
# Diagnostics de convergence des algos MCMC

- Les algorithmes MCMC produisent des chaînes de Markov **ergodiques** dont la loi stationnaire est la loi cible `\(f\)`

- Comment être sûr(e)/vérifier que la chaîne est bien dans son régime stationnaire ? 
 - **quand peut-on arrêter la chaîne ?**
 - **quelle est la précision obtenue?**

- Trois types d'outils diagnostics pour étudier :
 - la convergence de la chaîne vers le régime stationnaire
 - la convergence des moyennes
 - la convergence vers un échantillonnage i.i.d.

- Ce sont en général des .red[**conditions "nécessaires" mais pas suffisantes**]
&amp;rarr; permet de détecter un problème, mais ne garantit pas que tout s'est bien passé !



---
# Convergence vers la loi stationnaire (1)

- En pratique (et même en théorie !) il est difficile de tester si la chaîne produit des réalisations selon `\(f\)`
--

- Pour "tester" la convergence vers le régime stationnaire on peut utiliser des .red[**outils graphiques**] :
 - analyser le **trace plot** (évolution de la chaîne au cours des itérations) pour détecter les fortes non-stationnarités
&lt;img src="slides_25_files/figure-html/unnamed-chunk-145-1.png" width="720" style="display: block; margin: auto;" /&gt;


---
# Convergence vers la loi stationnaire (1)

- En pratique (et même en théorie !) il est difficile de tester si la chaîne produit des réalisations selon `\(f\)`
- Pour "tester" la convergence vers le régime stationnaire on peut utiliser des .red[**outils graphiques**] :
 - analyser le **trace plot** (évolution de la chaîne au cours des itérations) pour détecter les fortes non-stationnarités
 - lancer **plusieurs chaînes** (en parallèle) et comparer les résultats
&lt;img src="slides_25_files/figure-html/unnamed-chunk-146-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# Convergence vers la loi stationnaire (1)

.red[**Attention à l'effet "we only see where we've been"**]
&amp;rarr; exemple avec loi cible `\(0.7\mathcal{N}(1,1) + 0.2\mathcal{N}(6,1)\)` et MH à loi instrumentale `\(\mathcal{N}(0,1)\)`.

.pull-left[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-148-1.png" width="327.6" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-149-1.png" width="324" style="display: block; margin: auto;" /&gt;
]
.pull-left[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-150-1.png" width="327.6" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="slides_25_files/figure-html/unnamed-chunk-151-1.png" width="324" style="display: block; margin: auto;" /&gt;
]

---
# Convergence vers la loi stationnaire (2)

On peut aussi utiliser des .red[**tests de stationnarité**] :
- test de Kolmogorov-Smirnov (fonction `ks.test()` sous R et `scipy.stats.kstest()` sous Python)
 - attention aux hypothèses du test : .red[**échantillons i.i.d.**]
 
- test de Heidelberg et Welch (fonction `heidel.diag()` du package `coda` sous R)

- test de Geweke (fonction `geweke.diag()` dans `coda`)

- exploration du support de `\(f\)` &amp;rarr; si `\(f\)` connue exactement et si `\(d\)` petit
 - approximation par sommes de Riemann
 - estimation de la densité

---
class: my-one-page-font
# Convergence vers la loi stationnaire (3)

- En pratique, on définit aussi une période de chauffe (ou *burn-in*) correspondant aux premières itérations de l'algorithme
- Ces itérations sont **supprimées** et on ne garde que les itérations suivantes
&lt;img src="slides_25_files/figure-html/unnamed-chunk-152-1.png" width="504" style="display: block; margin: auto;" /&gt;

``` r
library(coda)
heidel.diag(X)
```

```
##                                    
##      Stationarity start     p-value
##      test         iteration        
## [,1] passed       1         0.124  
##                                 
##      Halfwidth Mean    Halfwidth
##      test                       
## [,1] failed    -0.0156 0.0415
```

---
# Convergence des moyennes empiriques (1)

- Si la chaîne a atteint son régime stationnaire, elle doit vérifier le *théorème ergodique*

- Autrement dit, toutes les expressions de la forme `\(\frac{1}{n}\sum_{i=1}^n h(X_n)\)` doivent converger vers `\(\mathbb{E}(h(X))\)` avec `\(X \sim f\)`.
- En pratique, on vérifie la stabilisation de ces quantités :
  - en traçant l'évolution de la moyenne cumulée 
  - idem pour les quantiles (fonction `cumuplot()` du package `coda`)
  - variance inter- et intra (plusieurs chaînes) &amp;rarr; fonction `gelman.diag()` du package `coda`



``` r
cumuplot(X)
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-154-1.png" width="720" style="display: block; margin: auto;" /&gt;

---
# Convergence vers un échantillonnage i.i.d.

On peut "mesurer" la proximité avec un échantillon i.i.d. :

- en calculant l'effective sampling size &amp;rarr; fonction `effectiveSamplingSize()` du package `coda`

- en traçant l'autocorrélation de la chaîne et en élagant


``` r
par(mfrow=c(1,2))
acf(X)
acf(X[500:2000])
```

&lt;img src="slides_25_files/figure-html/unnamed-chunk-155-1.png" width="576" style="display: block; margin: auto;" /&gt;


---
# Estimation de la variance

Sous certaines hypothèses d'ergodicité de la chaîne de Markov, elle vérifie un TCL :

`$$\sqrt{n} (\hat{\mu}_n - \mu) \longrightarrow \mathcal{N}(0,\sigma^2_{c})$$`

- expression de `\(\sigma^2_c\)`
- estimation de `\(\sigma_c^2\)`
 - par batch means
 - par méthodes spectrales
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
